# YOLOv12-BoT-SORT-ReID å¤šæ— äººæœºè·Ÿè¸ªç³»ç»Ÿ

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªå®Œæ•´çš„**å¤šæ— äººæœºç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ªç³»ç»Ÿ**ï¼ŒåŸºäºæœ€æ–°çš„ **YOLOv12** ç›®æ ‡æ£€æµ‹æ¨¡å‹å’Œ **BoT-SORT**ï¼ˆBottleneck Transformer SORTï¼‰å¤šç›®æ ‡è·Ÿè¸ªç®—æ³•ï¼Œç»“åˆ **Fast-ReID** é‡è¯†åˆ«æŠ€æœ¯ï¼Œå®ç°å¯¹æ— äººæœºé›†ç¾¤ï¼ˆUAV Swarmï¼‰çš„é«˜ç²¾åº¦æ£€æµ‹ã€è·Ÿè¸ªä¸è¯†åˆ«ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- âœ… **YOLOv12 ç›®æ ‡æ£€æµ‹**ï¼šæœ€æ–°çš„ YOLO ç³»åˆ—æ¨¡å‹ï¼Œæä¾›é«˜ç²¾åº¦å®æ—¶æ£€æµ‹
- âœ… **BoT-SORT è·Ÿè¸ªç®—æ³•**ï¼šç»“åˆç›¸æœºè¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰çš„å…ˆè¿›å¤šç›®æ ‡è·Ÿè¸ª
- âœ… **Fast-ReID é‡è¯†åˆ«**ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„ç›®æ ‡é‡è¯†åˆ«ï¼Œæé«˜è·Ÿè¸ªé²æ£’æ€§
- âœ… **å¤šæ•°æ®æ ¼å¼æ”¯æŒ**ï¼šæ”¯æŒ LabelMeã€UAVSwarmã€MOT Challenge ç­‰å¤šç§æ•°æ®æ ¼å¼
- âœ… **å®Œæ•´è®­ç»ƒæµç¨‹**ï¼šä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹è®­ç»ƒã€æ¨ç†ã€è¯„ä¼°çš„å…¨æµç¨‹æ”¯æŒ
- âœ… **æ‰¹é‡å¤„ç†èƒ½åŠ›**ï¼šæ”¯æŒæ‰¹é‡è§†é¢‘å¤„ç†å’Œå¤šåœºæ™¯è·Ÿè¸ª
- âœ… **è½¨è¿¹æ’å€¼ä¼˜åŒ–**ï¼šæä¾›è½¨è¿¹æ’å€¼ç®—æ³•ï¼Œä¼˜åŒ–è·Ÿè¸ªè¿ç»­æ€§

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
YOLOv12-BoT-SORT-ReID/
â”œâ”€â”€ convert_labelme_to_yolo.py      # LabelMe â†’ YOLO æ ¼å¼è½¬æ¢
â”œâ”€â”€ convert_uavswarm_to_yolo.py     # UAVSwarm â†’ YOLO æ ¼å¼è½¬æ¢
â”œâ”€â”€ evaluate_detections.py          # æ£€æµ‹ç»“æœè¯„ä¼°è„šæœ¬
â”œâ”€â”€ test_uavswarm.py                # å›¾åƒåºåˆ—æ£€æµ‹æµ‹è¯•
â”œâ”€â”€ BoT-SORT/                       # BoT-SORT è·Ÿè¸ªç³»ç»Ÿæ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ tracker/                    # è·Ÿè¸ªå™¨å®ç°
â”‚   â”‚   â”œâ”€â”€ bot_sort.py            # BoT-SORT ä¸»ç®—æ³•
â”‚   â”‚   â”œâ”€â”€ mc_bot_sort.py         # å¤šæ‘„åƒå¤´ BoT-SORT
â”‚   â”‚   â”œâ”€â”€ kalman_filter.py       # å¡å°”æ›¼æ»¤æ³¢å™¨
â”‚   â”‚   â”œâ”€â”€ gmc.py                 # å…¨å±€è¿åŠ¨è¡¥å¿
â”‚   â”‚   â””â”€â”€ matching.py            # æ•°æ®å…³è”åŒ¹é…
â”‚   â”œâ”€â”€ fast_reid/                  # Fast-ReID é‡è¯†åˆ«æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ fast_reid_interfece.py # ReID æ¥å£
â”‚   â”‚   â””â”€â”€ fastreid/              # ReID æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ yolov12/                    # YOLOv12 æ£€æµ‹æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ train.py               # æ¨¡å‹è®­ç»ƒè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ ultralytics/           # Ultralytics åº“
â”‚   â”‚   â”œâ”€â”€ weights/               # é¢„è®­ç»ƒæƒé‡
â”‚   â”‚   â””â”€â”€ *.yaml                 # æ•°æ®é›†é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ tools/                      # å·¥å…·è„šæœ¬é›†åˆ
â”‚   â”‚   â”œâ”€â”€ inference.py           # è§†é¢‘æ¨ç†ä¸è·Ÿè¸ª
â”‚   â”‚   â”œâ”€â”€ track.py               # MOT è¯„ä¼°è·Ÿè¸ª
â”‚   â”‚   â”œâ”€â”€ demo.py                # æ¼”ç¤ºè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ interpolation.py       # è½¨è¿¹æ’å€¼
â”‚   â”‚   â”œâ”€â”€ predict_track*.py      # å¤šèµ›é“é¢„æµ‹è„šæœ¬
â”‚   â”‚   â””â”€â”€ mota.py                # MOTA æŒ‡æ ‡è®¡ç®—
â”‚   â”œâ”€â”€ batch_process_videos.py    # æ‰¹é‡è§†é¢‘å¤„ç†
â”‚   â””â”€â”€ getInfo.py                 # æ•°æ®é›†ç»Ÿè®¡åˆ†æ
â”œâ”€â”€ data/                           # æ•°æ®é›†ç›®å½•
â”‚   â”œâ”€â”€ images/                    # åŸå§‹å›¾åƒæ•°æ®
â”‚   â”œâ”€â”€ uav_custom/                # è‡ªå®šä¹‰ UAV æ•°æ®é›†
â”‚   â”œâ”€â”€ uavswarm_yolo/             # UAVSwarm YOLO æ ¼å¼
â”‚   â”œâ”€â”€ MultiUAV_Train/            # å¤š UAV è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ MultiUAV_Test/             # å¤š UAV æµ‹è¯•æ•°æ®
â”‚   â””â”€â”€ MOT/                       # MOT æ ¼å¼æ•°æ®
â”œâ”€â”€ test_results/                   # æµ‹è¯•ç»“æœè¾“å‡º
â””â”€â”€ TrackEval/                      # è·Ÿè¸ªè¯„ä¼°å·¥å…·
    â”œâ”€â”€ trackeval/                 # è¯„ä¼°æŒ‡æ ‡å®ç°
    â””â”€â”€ scripts/                   # è¯„ä¼°è„šæœ¬

```

---

## ğŸ› ï¸ ç¯å¢ƒå®‰è£…

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šWindows 10/11, Linux (Ubuntu 18.04+)
- **Python**ï¼š3.8 - 3.11ï¼ˆæ¨è 3.11ï¼‰
- **GPU**ï¼šNVIDIA GPU with CUDA 11.0+ (æ¨è RTX 3060 åŠä»¥ä¸Š)
- **å†…å­˜**ï¼š16GB RAM åŠä»¥ä¸Š
- **ç¡¬ç›˜**ï¼š20GB å¯ç”¨ç©ºé—´

### å®‰è£…æ­¥éª¤

1. **å…‹éš†ä»“åº“**
```bash
git clone https://github.com/your-repo/YOLOv12-BoT-SORT-ReID.git
cd YOLOv12-BoT-SORT-ReID
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**ï¼ˆæ¨èï¼‰
```bash
conda create -n uav python=3.11
conda activate uav
```

3. **å®‰è£…ä¾èµ–åŒ…**
```bash
cd BoT-SORT
pip install -r requirements.txt
```

### æ ¸å¿ƒä¾èµ–åº“

```
ultralytics          # YOLOv12 å®˜æ–¹åº“
torch>=2.0.0         # PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
torchvision>=0.15.0  # è§†è§‰åº“
opencv-python        # å›¾åƒå¤„ç†
numpy                # æ•°å€¼è®¡ç®—
scipy                # ç§‘å­¦è®¡ç®—
filterpy             # å¡å°”æ›¼æ»¤æ³¢
lap                  # çº¿æ€§åˆ†é…é—®é¢˜æ±‚è§£å™¨
motmetrics           # MOT è¯„ä¼°æŒ‡æ ‡
loguru               # æ—¥å¿—è®°å½•
tqdm                 # è¿›åº¦æ¡æ˜¾ç¤º
scikit-learn         # æœºå™¨å­¦ä¹ å·¥å…·
matplotlib           # å¯è§†åŒ–
Pillow               # å›¾åƒå¤„ç†
easydict             # é…ç½®ç®¡ç†
pyyaml               # YAML è§£æ
```

---

## ğŸ“‚ æ•°æ®å‡†å¤‡

### 1. LabelMe æ ‡æ³¨æ•°æ®è½¬æ¢

**è„šæœ¬**ï¼š`convert_labelme_to_yolo.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å°† LabelMe å·¥å…·æ ‡æ³¨çš„ JSON æ–‡ä»¶è½¬æ¢ä¸º YOLO è®­ç»ƒæ ¼å¼
- è‡ªåŠ¨éå†å¤šçº§ç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰æ ‡æ³¨æ•°æ®
- éšæœºåˆ’åˆ†è®­ç»ƒé›†ï¼ˆ70%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ30%ï¼‰
- ç”Ÿæˆæ ‡å‡† YOLO ç›®å½•ç»“æ„

**ä½¿ç”¨æ–¹æ³•**ï¼š

1. ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„é…ç½®ï¼š
```python
base_dir = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\images"
output_images_train = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\images\train"
output_images_val = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\images\val"
output_labels_train = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\labels\train"
output_labels_val = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\labels\val"
```

2. è¿è¡Œè½¬æ¢è„šæœ¬ï¼š
```bash
python convert_labelme_to_yolo.py
```

**è¾“å…¥æ ¼å¼**ï¼š
- LabelMe JSON æ–‡ä»¶ï¼ˆçŸ©å½¢æ ‡æ³¨ï¼‰
- å¯¹åº”çš„ JPG/PNG å›¾åƒæ–‡ä»¶

**è¾“å‡ºæ ¼å¼**ï¼š
```
uav_custom/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/          # è®­ç»ƒå›¾åƒ
â”‚   â””â”€â”€ val/            # éªŒè¯å›¾åƒ
â””â”€â”€ labels/
    â”œâ”€â”€ train/          # è®­ç»ƒæ ‡ç­¾ (YOLO æ ¼å¼)
    â””â”€â”€ val/            # éªŒè¯æ ‡ç­¾ (YOLO æ ¼å¼)
```

**YOLO æ ‡ç­¾æ ¼å¼**ï¼š
```
class_id x_center y_center width height
0 0.5 0.5 0.3 0.4  # å½’ä¸€åŒ–åæ ‡ï¼ˆ0-1ï¼‰
```

---

### 2. UAVSwarm æ•°æ®é›†è½¬æ¢

**è„šæœ¬**ï¼š`convert_uavswarm_to_yolo.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å°† UAVSwarm æ•°æ®é›†çš„ MOT æ ¼å¼ï¼ˆgt.txtï¼‰è½¬æ¢ä¸º YOLO æ ¼å¼
- æ”¯æŒå¯è§æ€§å’Œç½®ä¿¡åº¦è¿‡æ»¤ï¼ˆvisibility > 0.3, conf > 0ï¼‰
- æŒ‰å¸§ç»„ç»‡æ•°æ®ï¼Œä¸ºæ¯ä¸€å¸§ç”Ÿæˆå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶
- è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†

**MOT æ ¼å¼è¯´æ˜**ï¼š
```
frame_id, track_id, x, y, w, h, conf, class_id, visibility
1, 1, 100, 200, 50, 80, 1.0, 0, 0.8
```

**ä½¿ç”¨æ–¹æ³•**ï¼š

1. ä¿®æ”¹è„šæœ¬é…ç½®ï¼š
```python
train_base_dir = "D:/UAV/YOLOv12-BoT-SORT-ReID/data/UAVSwarm-dataset-master/train"
test_base_dir = "D:/UAV/YOLOv12-BoT-SORT-ReID/data/UAVSwarm-dataset-master/test"
output_base = "D:/UAV/YOLOv12-BoT-SORT-ReID/data/uavswarm_yolo"
```

2. è¿è¡Œè½¬æ¢ï¼š
```bash
python convert_uavswarm_to_yolo.py
```

**è¾“å‡ºç»“æ„**ï¼š
```
uavswarm_yolo/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/          # è®­ç»ƒå›¾åƒï¼ˆä»è§†é¢‘åºåˆ—æå–ï¼‰
â”‚   â””â”€â”€ val/            # éªŒè¯å›¾åƒ
â””â”€â”€ labels/
    â”œâ”€â”€ train/          # å¯¹åº”æ ‡ç­¾
    â””â”€â”€ val/
```

---

### 3. æ•°æ®é›†é…ç½®æ–‡ä»¶

åˆ›å»º YAML é…ç½®æ–‡ä»¶ç”¨äºè®­ç»ƒï¼Œä¾‹å¦‚ `uav_custom.yaml`ï¼š

```yaml
train: D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\images\train
val: D:\UAV\YOLOv12-BoT-SORT-ReID\data\uav_custom\images\val
nc: 1
names: ['UAV']
```

---

## ğŸ“ æ¨¡å‹è®­ç»ƒ

### YOLOv12 è®­ç»ƒ

**è„šæœ¬**ï¼š`BoT-SORT/yolov12/train.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- åŸºäºé¢„è®­ç»ƒæƒé‡è¿›è¡Œè¿ç§»å­¦ä¹ 
- æ”¯æŒæ•°æ®å¢å¼ºï¼ˆMosaicã€Mixupï¼‰
- è‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
- çµæ´»çš„è¶…å‚æ•°é…ç½®

**è®­ç»ƒå‘½ä»¤**ï¼š

```bash
cd BoT-SORT/yolov12

# åŸºç¡€è®­ç»ƒ
python train.py --model_name ./weights/MOT_yolov12n.pt \
                --yaml_path uav_custom.yaml \
                --n_epoch 100 \
                --bs 64 \
                --imgsz 640

# å®Œæ•´å‚æ•°ç¤ºä¾‹
python train.py \
    --model_name ./weights/MOT_yolov12n.pt \
    --yaml_path uav_custom.yaml \
    --n_epoch 100 \
    --n_patience 50 \
    --bs 64 \
    --imgsz 640 \
    --single_cls True \
    --n_worker 8 \
    --save_path ./runs/uav \
    --lr0 0.01 \
    --lrf 0.01 \
    --mosaic 1.0 \
    --mixup 0.0 \
    --augment True
```

**å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|-----|------|--------|
| `--model_name` | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ | `./weights/MOT_yolov12n.pt` |
| `--yaml_path` | æ•°æ®é›†é…ç½®æ–‡ä»¶ | `uav.yaml` |
| `--n_epoch` | è®­ç»ƒè½®æ•° | 100 |
| `--n_patience` | æ—©åœè€å¿ƒå€¼ | 100 |
| `--bs` | æ‰¹æ¬¡å¤§å° | 64 |
| `--imgsz` | è¾“å…¥å›¾åƒå°ºå¯¸ | 640 |
| `--single_cls` | å•ç±»åˆ«æ¨¡å¼ | True |
| `--lr0` | åˆå§‹å­¦ä¹ ç‡ | 0.01 |
| `--lrf` | æœ€ç»ˆå­¦ä¹ ç‡ | 0.01 |
| `--mosaic` | Mosaic å¢å¼ºæ¯”ä¾‹ | 1.0 |
| `--mixup` | Mixup å¢å¼ºæ¯”ä¾‹ | 0.0 |

**è®­ç»ƒè¾“å‡º**ï¼š
- è®­ç»ƒæ—¥å¿—ï¼š`runs/uav/train*/`
- æœ€ä½³æƒé‡ï¼š`runs/uav/train*/weights/best.pt`
- æœ€åæƒé‡ï¼š`runs/uav/train*/weights/last.pt`

---

## ğŸ” æ¨¡å‹æ¨ç†ä¸æ£€æµ‹

### 1. å›¾åƒåºåˆ—æ£€æµ‹

**è„šæœ¬**ï¼š`test_uavswarm.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å¯¹å›¾åƒåºåˆ—è¿›è¡Œæ‰¹é‡æ£€æµ‹
- ç”Ÿæˆ MOT æ ¼å¼çš„æ£€æµ‹ç»“æœ
- ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
python test_uavswarm.py \
    --model_path BoT-SORT/yolov12/runs/uav/train/weights/best.pt \
    --image_folder data/UAVSwarm-dataset-master/test/UAVSwarm-02/img1 \
    --output_folder test_results/UAVSwarm-02 \
    --conf_threshold 0.3
```

**è¾“å‡ºæ–‡ä»¶**ï¼š
- `detections.txt`ï¼šMOT æ ¼å¼æ£€æµ‹ç»“æœ
- `vis/`ï¼šå¯è§†åŒ–ç»“æœå›¾åƒï¼ˆå¦‚æœå¯ç”¨ï¼‰

---

### 2. è§†é¢‘è·Ÿè¸ªæ¨ç†

**è„šæœ¬**ï¼š`BoT-SORT/tools/inference.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å®Œæ•´çš„æ£€æµ‹+è·Ÿè¸ªæµç¨‹
- æ”¯æŒè§†é¢‘æ–‡ä»¶å’Œå›¾åƒåºåˆ—
- é›†æˆ Fast-ReID é‡è¯†åˆ«
- æ”¯æŒå…¨å±€è¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰

**åŸºç¡€ä½¿ç”¨**ï¼š

```bash
cd BoT-SORT

python tools/inference.py \
    --weights ./yolov12/weights/v1/MOT_yolov12n.pt \
    --source ../data/MultiUAV_Train/TrainVideos/video001.mp4 \
    --img-size 1600 \
    --device 0 \
    --track_buffer 60 \
    --agnostic-nms \
    --save_path_answer ../test_results/video001
```

**é«˜çº§é…ç½®ï¼ˆå« ReIDï¼‰**ï¼š

```bash
python tools/inference.py \
    --weights ./yolov12/weights/v1/MOT_yolov12n.pt \
    --source ../data/MultiUAV_Train/TrainVideos/video001.mp4 \
    --img-size 1600 \
    --device 0 \
    --track_buffer 60 \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --agnostic-nms \
    --hide-labels-name \
    --nosave
```

**å…³é”®å‚æ•°**ï¼š

| å‚æ•° | è¯´æ˜ |
|-----|------|
| `--weights` | YOLOv12 æ¨¡å‹æƒé‡è·¯å¾„ |
| `--source` | è¾“å…¥è§†é¢‘/å›¾åƒåºåˆ—è·¯å¾„ |
| `--img-size` | æ¨ç†å›¾åƒå°ºå¯¸ï¼ˆ1600 é€‚åˆé«˜åˆ†è¾¨ç‡è§†é¢‘ï¼‰|
| `--device` | GPU è®¾å¤‡ IDï¼ˆ0, 1, ...ï¼‰æˆ– 'cpu' |
| `--track_buffer` | è·Ÿè¸ªç¼“å†²åŒºå¤§å°ï¼ˆå¸§æ•°ï¼‰|
| `--with-reid` | å¯ç”¨ Fast-ReID é‡è¯†åˆ« |
| `--fast-reid-config` | ReID æ¨¡å‹é…ç½®æ–‡ä»¶ |
| `--fast-reid-weights` | ReID æ¨¡å‹æƒé‡ |
| `--agnostic-nms` | ç±»åˆ«æ— å…³çš„ NMS |
| `--hide-labels-name` | éšè—æ ‡ç­¾åç§° |
| `--nosave` | ä¸ä¿å­˜å¯è§†åŒ–è§†é¢‘ï¼ˆä»…ä¿å­˜è·Ÿè¸ªç»“æœï¼‰|

---

### 3. æ‰¹é‡è§†é¢‘å¤„ç†

**è„šæœ¬**ï¼š`BoT-SORT/batch_process_videos.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- è‡ªåŠ¨éå†è§†é¢‘æ–‡ä»¶å¤¹
- æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²å¤„ç†è§†é¢‘ï¼‰
- æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯

**ä½¿ç”¨æ–¹æ³•**ï¼š

1. ä¿®æ”¹è„šæœ¬ä¸­çš„é…ç½®ï¼š
```python
video_folder = Path("D:/UAV/YOLOv12-BoT-SORT-ReID/data/MultiUAV_Train/TrainVideos")
output_dir = Path("D:/UAV/YOLOv12-BoT-SORT-ReID/TrackEval/data/trackers/mot_challenge/UAV-train/my_botsort/data")
```

2. è¿è¡Œæ‰¹å¤„ç†ï¼š
```bash
cd BoT-SORT
python batch_process_videos.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
Found 50 video files to process
============================================================
[1/50] Processing: video001.mp4
============================================================
âœ… video001.mp4 completed successfully in 45.3s
============================================================
[2/50] Processing: video002.mp4
============================================================
â­ï¸ video002.mp4 already processed, skipping...
...
```

---

## ğŸ“Š ç»“æœè¯„ä¼°

### 1. æ£€æµ‹ç²¾åº¦è¯„ä¼°

**è„šæœ¬**ï¼š`evaluate_detections.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- è®¡ç®—æ£€æµ‹æŒ‡æ ‡ï¼šPrecisionã€Recallã€F1-Scoreã€mAP@50
- æ”¯æŒ MOT æ ¼å¼çš„çœŸå€¼å’Œé¢„æµ‹æ¯”è¾ƒ
- å¯è®¾ç½®ä¸åŒçš„ IoU é˜ˆå€¼

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
python evaluate_detections.py \
    --pred_file test_results/UAVSwarm-02/detections.txt \
    --gt_file data/UAVSwarm-dataset-master/test/UAVSwarm-02/gt/gt.txt \
    --iou_threshold 0.5
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
ğŸ“Š Detection Evaluation Results
================================
Total Frames: 1500
Total GT Objects: 12500
Total Predictions: 12800

Precision: 0.8765
Recall: 0.8543
F1-Score: 0.8653
mAP@50: 0.8721
```

---

### 2. MOT æŒ‡æ ‡è¯„ä¼°

**å·¥å…·**ï¼šTrackEval

**åŠŸèƒ½è¯´æ˜**ï¼š
- è®¡ç®—æ ‡å‡† MOT æŒ‡æ ‡ï¼šHOTAã€MOTAã€IDF1
- æ”¯æŒå¤šåœºæ™¯æ‰¹é‡è¯„ä¼°
- ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š

**TrackEval è¯„ä¼°æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | è¯´æ˜ |
|-----|------|
| **HOTA** | Higher Order Tracking Accuracyï¼ˆé«˜é˜¶è·Ÿè¸ªç²¾åº¦ï¼‰|
| **MOTA** | Multiple Object Tracking Accuracyï¼ˆå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦ï¼‰|
| **IDF1** | Identification F1 Scoreï¼ˆèº«ä»½è¯†åˆ« F1 åˆ†æ•°ï¼‰|
| **DetA** | Detection Accuracyï¼ˆæ£€æµ‹ç²¾åº¦ï¼‰|
| **AssA** | Association Accuracyï¼ˆå…³è”ç²¾åº¦ï¼‰|
| **MT** | Mostly Trackedï¼ˆä¸»è¦è·Ÿè¸ªç›®æ ‡æ•°ï¼‰|
| **ML** | Mostly Lostï¼ˆä¸»è¦ä¸¢å¤±ç›®æ ‡æ•°ï¼‰|
| **FP** | False Positivesï¼ˆè¯¯æŠ¥ï¼‰|
| **FN** | False Negativesï¼ˆæ¼æŠ¥ï¼‰|
| **ID Sw.** | Identity Switchesï¼ˆID åˆ‡æ¢æ¬¡æ•°ï¼‰|

**ä½¿ç”¨TrackEval**ï¼š

```bash
cd TrackEval

python scripts/run_mot_challenge.py \
    --GT_FOLDER data/gt/mot_challenge/ \
    --TRACKERS_FOLDER data/trackers/mot_challenge/ \
    --TRACKER_SUB_FOLDER my_botsort \
    --BENCHMARK UAV-train \
    --SPLIT_TO_EVAL train \
    --METRICS HOTA CLEAR Identity
```

---

### 3. MOTA å¿«é€Ÿè¯„ä¼°

**è„šæœ¬**ï¼š`BoT-SORT/tools/mota.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å¿«é€Ÿè®¡ç®— MOTAã€MOTP ç­‰åŸºç¡€æŒ‡æ ‡
- é€‚åˆè°ƒè¯•å’Œå¿«é€ŸéªŒè¯

**ä½¿ç”¨æ–¹æ³•**ï¼š

ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„åè¿è¡Œï¼š
```bash
cd BoT-SORT
python tools/mota.py
```

---

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. è½¨è¿¹æ’å€¼ä¼˜åŒ–

**è„šæœ¬**ï¼š`BoT-SORT/tools/interpolation.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- å¯¹è·Ÿè¸ªç»“æœè¿›è¡Œè½¨è¿¹æ’å€¼
- å¡«è¡¥çŸ­æš‚çš„è·Ÿè¸ªé—´æ–­
- æé«˜è·Ÿè¸ªè¿ç»­æ€§å’Œ MOTA æŒ‡æ ‡

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
cd BoT-SORT

python tools/interpolation.py \
    --txt_path ../test_results/UAVSwarm-02 \
    --save_path ../test_results/UAVSwarm-02_interpolated \
    --n_min 5 \
    --n_dti 20
```

**å‚æ•°è¯´æ˜**ï¼š
- `--txt_path`ï¼šåŸå§‹è·Ÿè¸ªç»“æœç›®å½•
- `--save_path`ï¼šæ’å€¼åç»“æœä¿å­˜è·¯å¾„ï¼ˆNone åˆ™è¦†ç›–åŸæ–‡ä»¶ï¼‰
- `--n_min`ï¼šæœ€å°è½¨è¿¹é•¿åº¦ï¼ˆå°äºæ­¤å€¼çš„è½¨è¿¹ä¸è¿›è¡Œæ’å€¼ï¼‰
- `--n_dti`ï¼šæœ€å¤§æ’å€¼é—´éš”ï¼ˆå¸§æ•°ï¼‰

**æ’å€¼æ•ˆæœ**ï¼š
- å¡«è¡¥ 1-20 å¸§ä¹‹é—´çš„è·Ÿè¸ªç©ºç™½
- å‡å°‘ ID åˆ‡æ¢æ¬¡æ•°
- æé«˜æ•´ä½“è·Ÿè¸ªç¨³å®šæ€§

---

### 2. æ•°æ®é›†ç»Ÿè®¡åˆ†æ

**è„šæœ¬**ï¼š`BoT-SORT/getInfo.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- ç»Ÿè®¡æ•°æ®é›†çš„åŸºæœ¬ä¿¡æ¯
- åˆ†æç›®æ ‡å°ºå¯¸åˆ†å¸ƒ
- è®¡ç®—æ•°æ®é›†ç»Ÿè®¡æŒ‡æ ‡

**ä½¿ç”¨æ–¹æ³•**ï¼š

```python
# åœ¨è„šæœ¬ä¸­è°ƒç”¨ç›¸åº”å‡½æ•°
from getInfo import sot_train, mot_train

# SOT æ•°æ®é›†åˆ†æ
sot_train("data/SOT/train")

# MOT æ•°æ®é›†åˆ†æ
mot_train("data/MOT/train")
```

**è¾“å‡ºä¿¡æ¯**ï¼š
- åºåˆ—æ•°é‡ã€å¸§æ•°ç»Ÿè®¡
- ç›®æ ‡æ•°é‡å’Œå¯†åº¦
- è¾¹ç•Œæ¡†å°ºå¯¸åˆ†å¸ƒ
- å›¾åƒåˆ†è¾¨ç‡ç»Ÿè®¡

---

### 3. å…¨å±€è¿åŠ¨è¡¥å¿ï¼ˆGMCï¼‰

**æ¨¡å—**ï¼š`BoT-SORT/tracker/gmc.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- è¡¥å¿æ‘„åƒæœºè¿åŠ¨é€ æˆçš„ä½ç½®åç§»
- æé«˜æ— äººæœºèˆªæ‹åœºæ™¯çš„è·Ÿè¸ªç²¾åº¦
- æ”¯æŒå¤šç§æ–¹æ³•ï¼šORBã€ECCã€OpticalFlow

**GMC æ–¹æ³•**ï¼š

| æ–¹æ³• | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|-----|------|---------|
| `file` | ä»æ–‡ä»¶è¯»å–ç›¸æœºè¿åŠ¨å‚æ•° | å·²çŸ¥ç›¸æœºè¿åŠ¨ |
| `orb` | ORB ç‰¹å¾åŒ¹é… | ä¸€èˆ¬åœºæ™¯ |
| `ecc` | å¢å¼ºç›¸å…³ç³»æ•° | çº¹ç†ä¸°å¯Œåœºæ™¯ |
| `sparseOptFlow` | ç¨€ç–å…‰æµ | å¿«é€Ÿè¿åŠ¨ |
| `none` | ä¸ä½¿ç”¨ GMC | é™æ€ç›¸æœº |

**åœ¨ inference.py ä¸­ä½¿ç”¨**ï¼š
```bash
python tools/inference.py \
    --cmc-method orb \
    ... # å…¶ä»–å‚æ•°
```

---

### 4. å¤šæ‘„åƒå¤´è·Ÿè¸ª

**æ¨¡å—**ï¼š`BoT-SORT/tracker/mc_bot_sort.py`

**åŠŸèƒ½è¯´æ˜**ï¼š
- æ”¯æŒå¤šæ‘„åƒå¤´åœºæ™¯çš„ç›®æ ‡è·Ÿè¸ª
- è·¨æ‘„åƒå¤´çš„ç›®æ ‡é‡è¯†åˆ«
- å…¨å±€ ID ç®¡ç†

**ä½¿ç”¨åœºæ™¯**ï¼š
- å¤šæ— äººæœºååŒç›‘æ§
- å¤§èŒƒå›´åŒºåŸŸè¦†ç›–
- ç›®æ ‡è·¨è§†é‡è·Ÿè¸ª

---

## ğŸ¯ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

### åœºæ™¯ï¼šä»æ•°æ®æ ‡æ³¨åˆ°æ¨¡å‹éƒ¨ç½²

```bash
# 1. æ•°æ®å‡†å¤‡ï¼šè½¬æ¢ LabelMe æ ‡æ³¨
python convert_labelme_to_yolo.py

# 2. æ¨¡å‹è®­ç»ƒ
cd BoT-SORT/yolov12
python train.py --model_name ./weights/MOT_yolov12n.pt \
                --yaml_path uav_custom.yaml \
                --n_epoch 100 \
                --bs 64

# 3. å•åºåˆ—æ£€æµ‹æµ‹è¯•
cd ../..
python test_uavswarm.py \
    --model_path BoT-SORT/yolov12/runs/uav/train/weights/best.pt \
    --image_folder data/test/sequence_01 \
    --output_folder test_results/sequence_01

# 4. æ£€æµ‹ç»“æœè¯„ä¼°
python evaluate_detections.py \
    --pred_file test_results/sequence_01/detections.txt \
    --gt_file data/test/sequence_01/gt/gt.txt

# 5. è§†é¢‘è·Ÿè¸ªï¼ˆå« ReIDï¼‰
cd BoT-SORT
python tools/inference.py \
    --weights ./yolov12/runs/uav/train/weights/best.pt \
    --source ../data/test_video.mp4 \
    --img-size 1600 \
    --device 0 \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth

# 6. è½¨è¿¹æ’å€¼ä¼˜åŒ–
python tools/interpolation.py \
    --txt_path ../test_results/track_output \
    --n_min 5 \
    --n_dti 20

# 7. MOT æŒ‡æ ‡è¯„ä¼°
cd ../TrackEval
python scripts/run_mot_challenge.py \
    --GT_FOLDER data/gt/mot_challenge/ \
    --TRACKERS_FOLDER data/trackers/mot_challenge/ \
    --TRACKER_SUB_FOLDER my_botsort \
    --METRICS HOTA CLEAR Identity
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. è®­ç»ƒä¼˜åŒ–

- **æ•°æ®å¢å¼º**ï¼šå¯ç”¨ Mosaic (1.0) å’Œé€‚é‡ Mixup (0.1-0.2)
- **å›¾åƒå°ºå¯¸**ï¼šé«˜åˆ†è¾¨ç‡è§†é¢‘ä½¿ç”¨ 1280 æˆ– 1600
- **æ‰¹æ¬¡å¤§å°**ï¼šæ ¹æ® GPU æ˜¾å­˜è°ƒæ•´ï¼ˆRTX 3090: 64-128ï¼‰
- **å­¦ä¹ ç‡**ï¼šä½¿ç”¨ä½™å¼¦é€€ç«ï¼Œåˆå§‹ 0.01ï¼Œæœ€ç»ˆ 0.001

### 2. æ¨ç†ä¼˜åŒ–

- **ç½®ä¿¡åº¦é˜ˆå€¼**ï¼š0.3-0.5ï¼ˆæ ¹æ®åœºæ™¯è°ƒæ•´ï¼‰
- **NMS é˜ˆå€¼**ï¼š0.4-0.5
- **è·Ÿè¸ªç¼“å†²åŒº**ï¼š30-60 å¸§ï¼ˆæ ¹æ®è§†é¢‘å¸§ç‡ï¼‰
- **å›¾åƒå°ºå¯¸**ï¼šæ¨ç†æ—¶å¯ä»¥å¤§äºè®­ç»ƒå°ºå¯¸ï¼ˆå¦‚ 1600ï¼‰

### 3. è·Ÿè¸ªä¼˜åŒ–

- **å¯ç”¨ ReID**ï¼šæé«˜é®æŒ¡åçš„é‡è¯†åˆ«èƒ½åŠ›
- **å¯ç”¨ GMC**ï¼šè¡¥å¿æ‘„åƒæœºè¿åŠ¨
- **è°ƒæ•´åŒ¹é…é˜ˆå€¼**ï¼šmatch_thresh (0.7-0.9)
- **è½¨è¿¹æ’å€¼**ï¼šn_dti è®¾ç½®ä¸º 10-30 å¸§

---

## â“ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒæ—¶æ˜¾å­˜ä¸è¶³ï¼Ÿ
**A:** å‡å°æ‰¹æ¬¡å¤§å° `--bs 32` æˆ–å›¾åƒå°ºå¯¸ `--imgsz 320`

### Q2: æ¨ç†é€Ÿåº¦æ…¢ï¼Ÿ
**A:** 
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆyolov12n è€Œé yolov12xï¼‰
- é™ä½è¾“å…¥å›¾åƒå°ºå¯¸
- ä½¿ç”¨ GPU åŠ é€Ÿ `--device 0`
- ç¦ç”¨å¯è§†åŒ– `--nosave`

### Q3: è·Ÿè¸ªæ•ˆæœä¸ä½³ï¼Ÿ
**A:**
- é™ä½æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
- å¢åŠ è·Ÿè¸ªç¼“å†²åŒº `--track_buffer 60`
- å¯ç”¨ ReID `--with-reid`
- ä½¿ç”¨ GMC è¡¥å¿ç›¸æœºè¿åŠ¨

### Q4: ID åˆ‡æ¢é¢‘ç¹ï¼Ÿ
**A:**
- å¯ç”¨ Fast-ReID é‡è¯†åˆ«
- å¢å¤§åŒ¹é…é˜ˆå€¼ `--match_thresh 0.9`
- ä½¿ç”¨è½¨è¿¹æ’å€¼åå¤„ç†
- è°ƒæ•´å¤–è§‚ç›¸ä¼¼åº¦é˜ˆå€¼

### Q5: å¦‚ä½•å¤„ç†å°ç›®æ ‡ï¼Ÿ
**A:**
- å¢å¤§è¾“å…¥å›¾åƒå°ºå¯¸ `--img-size 1600`
- è°ƒä½ `--min_box_area 5`
- ä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒ
- å¢å¼ºæ•°æ®é›†ä¸­çš„å°ç›®æ ‡æ ·æœ¬

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡

1. **YOLOv12**: [å¾…å‘å¸ƒ]
2. **BoT-SORT**: [Robust Multi-Object Tracking by Marginal Inference](https://arxiv.org/abs/2206.14651)
3. **Fast-ReID**: [FastReID: A Pytorch Toolbox for General Instance Re-identification](https://arxiv.org/abs/2006.02631)
4. **HOTA Metrics**: [HOTA: A Higher Order Metric for Evaluating Multi-Object Tracking](https://link.springer.com/article/10.1007/s11263-020-01375-2)

### ç›¸å…³é¡¹ç›®

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [BoT-SORT Official](https://github.com/NirAharon/BoT-SORT)
- [Fast-ReID](https://github.com/JDAI-CV/fast-reid)
- [TrackEval](https://github.com/JonathonLuiten/TrackEval)

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å‘å¸ƒã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ‘¥ ä½œè€…ä¸è‡´è°¢

**é¡¹ç›®ç»´æŠ¤è€…**ï¼š[æ‚¨çš„åå­—]

**ç‰¹åˆ«æ„Ÿè°¢**ï¼š
- Ultralytics å›¢é˜Ÿæä¾›çš„ YOLOv8/YOLOv12 æ¡†æ¶
- BoT-SORT ä½œè€…çš„å¼€æºè´¡çŒ®
- Fast-ReID å›¢é˜Ÿçš„é‡è¯†åˆ«æ¨¡å‹
- TrackEval å·¥å…·çš„å¼€å‘è€…

---

## ğŸ“§ è”ç³»æ–¹å¼

- é‚®ç®±ï¼šyour.email@example.com
- GitHub Issuesï¼š[é¡¹ç›® Issues é¡µé¢](https://github.com/your-repo/issues)

---

## ğŸ”„ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-11-25)
- âœ… å®Œæ•´çš„æ•°æ®è½¬æ¢å·¥å…·ï¼ˆLabelMeã€UAVSwarmï¼‰
- âœ… YOLOv12 è®­ç»ƒå’Œæ¨ç†æµç¨‹
- âœ… BoT-SORT å¤šç›®æ ‡è·Ÿè¸ª
- âœ… Fast-ReID é‡è¯†åˆ«é›†æˆ
- âœ… TrackEval è¯„ä¼°å·¥å…·
- âœ… æ‰¹é‡è§†é¢‘å¤„ç†
- âœ… è½¨è¿¹æ’å€¼ä¼˜åŒ–
- âœ… å®Œæ•´æ–‡æ¡£å’Œç¤ºä¾‹

---

**ğŸ‰ ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æ Issueï¼**

### ä½¿ç”¨æ–¹æ³•

```- `ultralytics` - YOLOv12 æ¨¡å‹åº“

ç¼–è¾‘è„šæœ¬ä¸­çš„å‚æ•°ï¼š

```python

model_path = r'D:\path\to\best.pt'              # æ¨¡å‹æƒé‡

image_folder = r'D:\path\to\images'             # è¾“å…¥å›¾åƒæ–‡ä»¶å¤¹**ä½¿ç”¨æ–¹æ³•**ï¼šç¼–è¾‘è„šæœ¬ä¸­çš„è·¯å¾„é…ç½®åè¿è¡Œï¼š- `torch` / `torchvision` - æ·±åº¦å­¦ä¹ æ¡†æ¶### 2.1 LabelMe æ ¼å¼è½¬æ¢```bash

output_folder = r'D:\path\to\output'            # è¾“å‡ºç»“æœç›®å½•

conf_threshold = 0.3                             # ç½®ä¿¡åº¦é˜ˆå€¼```bash

```

python convert_labelme_to_yolo.py- `opencv-python` - å›¾åƒå¤„ç†

è¿è¡Œæ¨ç†ï¼š

```bash```

python test_uavswarm.py

```- `numpy` - æ•°å€¼è®¡ç®—å¦‚æœä½ ä½¿ç”¨ LabelMe å·¥å…·è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œç”Ÿæˆçš„ JSON æ–‡ä»¶å¯ä»¥é€šè¿‡æ­¤è„šæœ¬è½¬æ¢ä¸º YOLO æ ¼å¼çš„ TXT æ ‡ç­¾ã€‚



### è¾“å‡ºè¯´æ˜**è¾“å‡ºç»“æ„**ï¼š



- **detections.txt**ï¼šMOT æ ¼å¼çš„æ£€æµ‹ç»“æœæ–‡ä»¶```- `tqdm` - è¿›åº¦æ¡

- **vis_*.jpg**ï¼šå¯è§†åŒ–å›¾åƒ

uav_custom/

**detections.txt æ ¼å¼**ï¼š

```â”œâ”€â”€ images/pip install -r BoT-SORT/requirements.txt

1,-1,123.5,98.2,45.0,52.1,0.95,-1,-1,-1

1,-1,345.8,210.3,38.5,48.9,0.87,-1,-1,-1â”‚   â”œâ”€â”€ train/  # è®­ç»ƒé›†å›¾ç‰‡ï¼ˆ70%ï¼‰

2,-1,125.3,100.1,44.5,51.8,0.92,-1,-1,-1

```â”‚   â””â”€â”€ val/    # éªŒè¯é›†å›¾ç‰‡ï¼ˆ30%ï¼‰## ğŸ“‚ æ•°æ®å‡†å¤‡



---â””â”€â”€ labels/



## ğŸ“Š ç»“æœè¯„ä¼°    â”œâ”€â”€ train/  # è®­ç»ƒé›†æ ‡ç­¾- **è„šæœ¬**: `convert_labelme_to_yolo.py`



**è„šæœ¬**ï¼š`evaluate_detections.py`    â””â”€â”€ val/    # éªŒè¯é›†æ ‡ç­¾



### åŠŸèƒ½è¯´æ˜```### 2.1 LabelMe æ ‡æ³¨æ•°æ®è½¬æ¢



å¯¹æ¯”é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼Œè®¡ç®—æ£€æµ‹ç²¾åº¦æŒ‡æ ‡ï¼š



1. **è§£ææ–‡ä»¶**ï¼šè¯»å–é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼ˆéƒ½æ˜¯ MOT æ ¼å¼ï¼‰---- **åŠŸèƒ½**: ```

2. **IOU åŒ¹é…**ï¼šè®¡ç®—é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„äº¤å¹¶æ¯”

3. **è®¡ç®—æŒ‡æ ‡**ï¼šTPï¼ˆçœŸæ­£ä¾‹ï¼‰ã€FPï¼ˆå‡æ­£ä¾‹ï¼‰ã€FNï¼ˆå‡è´Ÿä¾‹ï¼‰

4. **ç”ŸæˆæŠ¥å‘Š**ï¼šè¾“å‡ºç²¾åº¦ã€å¬å›ç‡ã€F1 åˆ†æ•°ç­‰æŒ‡æ ‡

5. **é€å¸§å¯¹æ¯”**ï¼šéšæœºé‡‡æ ·æ˜¾ç¤ºéƒ¨åˆ†å¸§çš„è¯¦ç»†å¯¹æ¯”### 2.2 UAVSwarm æ•°æ®é›†è½¬æ¢**åœºæ™¯**ï¼šä½ ä½¿ç”¨ LabelMe å·¥å…·å¯¹å›¾åƒè¿›è¡Œäº†çŸ©å½¢æ ‡æ³¨ï¼Œç”Ÿæˆäº† JSON æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶ã€‚



### è®¡ç®—çš„æŒ‡æ ‡



| æŒ‡æ ‡ | å…¬å¼ | è¯´æ˜ |**åœºæ™¯**ï¼šæœ‰ UAVSwarm æ•°æ®é›†ï¼ˆMOT Challenge æ ¼å¼ï¼‰ï¼ŒåŒ…å« `train/` å’Œ `test/` ç›®å½•ã€‚  - éå†æŒ‡å®šç›®å½•ä¸‹çš„ JSON æ–‡ä»¶ã€‚

|-----|------|------|

| **Precision** | TP / (TP + FP) | æ£€æµ‹å‡†ç¡®ç‡ |

| **Recall** | TP / (TP + FN) | æ£€æµ‹å¬å›ç‡ |

| **F1-Score** | 2 Ã— P Ã— R / (P + R) | ç²¾åº¦å’Œå¬å›çš„è°ƒå’Œå¹³å‡æ•° |**è„šæœ¬**ï¼š`convert_uavswarm_to_yolo.py`**è„šæœ¬**ï¼š`convert_labelme_to_yolo.py`

| **Detection Rate** | TP / Total_GT | ç›®æ ‡æ£€æµ‹ç‡ |

| **False Alarm Rate** | FP / Total_Pred | è¯¯æ£€ç‡ |



### ä½¿ç”¨æ–¹æ³•**åŠŸèƒ½**ï¼š  - å°†çŸ©å½¢æ ‡æ³¨è½¬æ¢ä¸º YOLO å½’ä¸€åŒ–åæ ‡ (class x_center y_center w h)ã€‚



ç¼–è¾‘è„šæœ¬ä¸­çš„æ–‡ä»¶è·¯å¾„ï¼š- è¯»å– MOT æ ¼å¼çš„ `gt.txt` æ–‡ä»¶

```python

pred_file = r'D:\path\to\detections.txt'     # é¢„æµ‹ç»“æœ- è¿‡æ»¤æœºåˆ¶ï¼šåªä¿ç•™å¯è§æ€§ > 0.3 å’Œç½®ä¿¡åº¦ > 0 çš„ç›®æ ‡**åŠŸèƒ½**ï¼š

gt_file = r'D:\path\to\gt.txt'               # çœŸå®æ ‡æ³¨

```- æŒ‰å¸§å·åˆ†ç»„ï¼Œä¸ºæ¯å¸§ç”Ÿæˆ YOLO æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶



è¿è¡Œè¯„ä¼°ï¼š- è‡ªåŠ¨æ‰«ææ‰€æœ‰åºåˆ—ï¼Œéšæœºåˆ†å‰²ä¸ºè®­ç»ƒé›†ï¼ˆ70%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ30%ï¼‰- è§£æ LabelMe ç”Ÿæˆçš„ JSON æ ‡æ³¨æ–‡ä»¶  - è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œå¹¶ç§»åŠ¨å›¾ç‰‡ã€‚

```bash

python evaluate_detections.py- ç”Ÿæˆ YOLO è®­ç»ƒæ‰€éœ€çš„ç»“æ„

```

- æå–çŸ©å½¢æ ‡æ³¨çš„åæ ‡ï¼Œè½¬æ¢ä¸º YOLO æ ¼å¼ï¼ˆå½’ä¸€åŒ–çš„ç±»åˆ«å’Œä¸­å¿ƒåæ ‡ï¼‰

---

**MOT æ ¼å¼è¯´æ˜**ï¼š

## ğŸš€ æ ¸å¿ƒæ¨¡å—è¯´æ˜

```- è‡ªåŠ¨æ‰«æç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼Œæ”¶é›†æ‰€æœ‰ JSON æ–‡ä»¶å’Œå¯¹åº”çš„å›¾ç‰‡- **è¿è¡Œ**:## 2. æ•°æ®å‡†å¤‡[![arXiv](https://img.shields.io/badge/arXiv-2503.17237-b31b1b.svg)](https://arxiv.org/abs/2503.17237)

### BoT-SORT è·Ÿè¸ªå™¨

frame_id, track_id, x, y, w, h, conf, class_id, visibility

ä½ç½®ï¼š`BoT-SORT/tracker/`

1,1,100,50,30,50,1,-1,0.9- å°†æ•°æ®éšæœºåˆ†å‰²ä¸ºè®­ç»ƒé›†ï¼ˆ70%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ30%ï¼‰

**ä¸»è¦ç»„ä»¶**ï¼š

- **bot_sort.py**ï¼šæ ¸å¿ƒè·Ÿè¸ªç®—æ³•```

  - ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢é¢„æµ‹è½¨è¿¹

  - æå–ç›®æ ‡å¤–è§‚ç‰¹å¾ï¼ˆReIDï¼‰- åˆ›å»ºæ ‡å‡†çš„ YOLO ç›®å½•ç»“æ„ï¼š`images/train`, `images/val`, `labels/train`, `labels/val`  ```bash

  - è¿›è¡Œè½¨è¿¹åŒ¹é…

  **ä½¿ç”¨æ–¹æ³•**ï¼š

- **kalman_filter.py**ï¼šå¡å°”æ›¼æ»¤æ³¢å™¨

  - é¢„æµ‹ç›®æ ‡ä½ç½®å’Œé€Ÿåº¦```bash

  

- **matching.py**ï¼šè½¨è¿¹åŒ¹é…ç®—æ³•python convert_uavswarm_to_yolo.py

  - Hungarian ç®—æ³•è¿›è¡ŒäºŒéƒ¨å›¾åŒ¹é…

  - IOU ç›¸ä¼¼åº¦è®¡ç®—```**YOLO æ ‡ç­¾æ ¼å¼**ï¼š  python convert_labelme_to_yolo.py[![PyPI - Python Version](https://img.shields.io/badge/python-3.11-blue.svg?logo=python&logoColor=gold)](https://www.python.org/downloads/release/python-3110/)

  - ç‰¹å¾è·ç¦»è®¡ç®—



- **gmc.py**ï¼šå…¨å±€è¿åŠ¨è¡¥å¿

  - å¤„ç†æ‘„åƒæœºè¿åŠ¨**è¾“å‡ºç»“æ„**ï¼š```



### YOLOv12 æ£€æµ‹æ¨¡å‹```



ä½ç½®ï¼š`BoT-SORT/yolov12/`uavswarm_yolo/class_id x_center y_center width height  ```



**ä¸»è¦åŠŸèƒ½**ï¼šâ”œâ”€â”€ images/

- **train.py**ï¼šæ¨¡å‹è®­ç»ƒè„šæœ¬

- **é…ç½®æ–‡ä»¶**ï¼ˆYAMLï¼‰ï¼šâ”‚   â”œâ”€â”€ train/  # æ‰€æœ‰åºåˆ—çš„è®­ç»ƒå›¾ç‰‡0 0.5 0.5 0.3 0.4  # å½’ä¸€åŒ–åæ ‡ï¼ˆ0-1ï¼‰

  - `uav.yaml` - é»˜è®¤ UAV æ•°æ®é›†é…ç½®

  - `uav_custom.yaml` - è‡ªå®šä¹‰ UAV æ•°æ®é›†é…ç½®â”‚   â””â”€â”€ val/    # æ‰€æœ‰åºåˆ—çš„éªŒè¯å›¾ç‰‡

  - `uavswarm.yaml` - UAVSwarm æ•°æ®é›†é…ç½®

â””â”€â”€ labels/```  *æ³¨æ„ï¼šéœ€åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `base_dir` å’Œè¾“å‡ºè·¯å¾„ã€‚*é¡¹ç›®æ•°æ®å­˜æ”¾åœ¨ `data/` ç›®å½•ä¸‹ã€‚æä¾›äº†ä»¥ä¸‹è„šæœ¬ç”¨äºæ•°æ®æ ¼å¼è½¬æ¢ï¼š[![Hugging Face Demo](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/wish44165/YOLOv12-BoT-SORT-ReID) 

**è®­ç»ƒå‘½ä»¤ç¤ºä¾‹**ï¼š

```bash    â”œâ”€â”€ train/  # å¯¹åº”çš„è®­ç»ƒæ ‡ç­¾

cd BoT-SORT/yolov12/

python train.py --model_name weights/MOT_yolov12n.pt \    â””â”€â”€ val/    # å¯¹åº”çš„éªŒè¯æ ‡ç­¾

                 --yaml_path uav.yaml \

                 --n_epoch 100 \```

                 --bs 32

```**ä½¿ç”¨æ–¹æ³•**ï¼š



### FastReID ç‰¹å¾æå–---



ä½ç½®ï¼š`BoT-SORT/fast_reid/`



**åŠŸèƒ½**ï¼š## ğŸ” æ¨¡å‹æ¨ç†ä¸æ£€æµ‹

- æå–ç›®æ ‡å¤–è§‚ç‰¹å¾

- ç”¨äºè½¨è¿¹å…³è”çš„ç‰¹å¾åŒ¹é…ç¼–è¾‘è„šæœ¬ä¸­çš„è·¯å¾„é…ç½®ï¼š### 2.2 UAVSwarm æ•°æ®é›†è½¬æ¢[![Colab Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1x5T6woUdV6dD_T6qdYcKG04Q2iVVHGoD?usp=sharing)

- æ”¯æŒç‰¹å¾è·ç¦»è®¡ç®—

**è„šæœ¬**ï¼š`test_uavswarm.py`

---

```python

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

### åŠŸèƒ½è¯´æ˜

```

YOLOv12-BoT-SORT-ReID/base_dir = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\images"  # è¾“å…¥ï¼šåŒ…å« JSON çš„ç›®å½•é’ˆå¯¹ UAVSwarm æ•°æ®é›†ï¼ˆMOT æ ¼å¼ï¼‰ï¼Œå°†å…¶è½¬æ¢ä¸º YOLO è®­ç»ƒæ‰€éœ€çš„å›¾ç‰‡å’Œæ ‡ç­¾æ ¼å¼ã€‚

â”‚

â”œâ”€â”€ BoT-SORT/ä½¿ç”¨å·²è®­ç»ƒçš„ YOLOv12 æ¨¡å‹å¯¹å›¾åƒåºåˆ—è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼š

â”‚   â”œâ”€â”€ yolov12/                    # YOLOv12 æ£€æµ‹æ¨¡å‹

â”‚   â”‚   â”œâ”€â”€ train.pyoutput_images_train = r"..."  # è¾“å‡ºè®­ç»ƒé›†å›¾ç‰‡

â”‚   â”‚   â”œâ”€â”€ weights/

â”‚   â”‚   â”œâ”€â”€ models/1. **åŠ è½½æ¨¡å‹**ï¼šä» `.pt` æƒé‡æ–‡ä»¶åŠ è½½ YOLOv12 æ¨¡å‹

â”‚   â”‚   â””â”€â”€ ultralytics/

â”‚   â”‚2. **æ‰¹é‡æ¨ç†**ï¼šéå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒï¼ˆæ”¯æŒ .jpg, .jpeg, .png, .bmpï¼‰output_images_val = r"..."    # è¾“å‡ºéªŒè¯é›†å›¾ç‰‡- **LabelMe è½¬ YOLO**:[![Kaggle Notebook](https://img.shields.io/badge/Kaggle-Notebook-blue?logo=kaggle)](https://www.kaggle.com/code/yuhsi44165/yolov12-bot-sort/)

â”‚   â”œâ”€â”€ tracker/                    # BoT-SORT è·Ÿè¸ªå™¨

â”‚   â”‚   â”œâ”€â”€ bot_sort.py3. **ç”Ÿæˆæ£€æµ‹ç»“æœ**ï¼š

â”‚   â”‚   â”œâ”€â”€ kalman_filter.py

â”‚   â”‚   â”œâ”€â”€ matching.py   - ä¿å­˜ä¸º **MOT æ ¼å¼** çš„ TXT æ–‡ä»¶ (`detections.txt`)output_labels_train = r"..."  # è¾“å‡ºè®­ç»ƒé›†æ ‡ç­¾

â”‚   â”‚   â”œâ”€â”€ gmc.py

â”‚   â”‚   â””â”€â”€ tracking_utils/   - æ¯è¡Œä¸€ä¸ªæ£€æµ‹æ¡†ï¼š`frame_id, -1, x, y, w, h, conf, -1, -1, -1`

â”‚   â”‚

â”‚   â”œâ”€â”€ fast_reid/                  # FastReID ç‰¹å¾æå–4. **å¯è§†åŒ–**ï¼šåœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œç½®ä¿¡åº¦ï¼Œä¿å­˜ä¸º `vis_*.jpg`output_labels_val = r"..."    # è¾“å‡ºéªŒè¯é›†æ ‡ç­¾- **è„šæœ¬**: `convert_uavswarm_to_yolo.py`

â”‚   â”‚   â”œâ”€â”€ fast_reid_interfece.py

â”‚   â”‚   â”œâ”€â”€ fastreid/

â”‚   â”‚   â”œâ”€â”€ projects/

â”‚   â”‚   â””â”€â”€ logs/### ä½¿ç”¨æ–¹æ³•```

â”‚   â”‚

â”‚   â”œâ”€â”€ tools/                      # å·¥å…·è„šæœ¬

â”‚   â”‚   â”œâ”€â”€ track.py

â”‚   â”‚   â”œâ”€â”€ predict_track1/2/3.pyç¼–è¾‘è„šæœ¬ä¸­çš„å‚æ•°ï¼š- **åŠŸèƒ½**:  å¦‚æœä½ ä½¿ç”¨ LabelMe è¿›è¡Œæ ‡æ³¨ï¼Œå¯ä»¥ä½¿ç”¨ `convert_labelme_to_yolo.py` å°† JSON æ–‡ä»¶è½¬æ¢ä¸º YOLO æ ¼å¼çš„ TXT æ ‡ç­¾ã€‚

â”‚   â”‚   â”œâ”€â”€ inference.py

â”‚   â”‚   â”œâ”€â”€ mota.py```python

â”‚   â”‚   â””â”€â”€ demo.py

â”‚   â”‚model_path = r'D:\path\to\best.pt'              # æ¨¡å‹æƒé‡ç„¶åè¿è¡Œï¼š

â”‚   â”œâ”€â”€ cocoapi/                    # COCO API

â”‚   â”œâ”€â”€ datasets/                   # æ•°æ®é›†é…ç½®image_folder = r'D:\path\to\images'             # è¾“å…¥å›¾åƒæ–‡ä»¶å¤¹

â”‚   â”œâ”€â”€ logs/                       # è®­ç»ƒæ—¥å¿—

â”‚   â”œâ”€â”€ runs/                       # æ¨ç†è¾“å‡ºoutput_folder = r'D:\path\to\output'            # è¾“å‡ºç»“æœç›®å½•```bash  - è¯»å– MOT æ ¼å¼çš„ `gt.txt`ã€‚

â”‚   â”œâ”€â”€ submit/                     # æäº¤ç»“æœ

â”‚   â”œâ”€â”€ VideoCameraCorrection/      # æ‘„åƒæœºçŸ«æ­£conf_threshold = 0.3                             # ç½®ä¿¡åº¦é˜ˆå€¼

â”‚   â””â”€â”€ requirements.txt

â”‚```python convert_labelme_to_yolo.py

â”œâ”€â”€ data/

â”‚   â”œâ”€â”€ images/                     # åŸå§‹å›¾åƒ

â”‚   â”œâ”€â”€ labels/                     # æ ‡æ³¨æ ‡ç­¾

â”‚   â”œâ”€â”€ demo/                       # æ¼”ç¤ºæ•°æ®è¿è¡Œæ¨ç†ï¼š```  - è¿‡æ»¤ä½å¯è§åº¦å’Œä½ç½®ä¿¡åº¦çš„ç›®æ ‡ã€‚  ```bash<a href="https://doi.org/10.5281/zenodo.15203123"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.15203123.svg" alt="DOI"></a>

â”‚   â”œâ”€â”€ uav_custom/                 # LabelMe è½¬æ¢æ•°æ®

â”‚   â”œâ”€â”€ uavswarm_yolo/              # UAVSwarm è½¬æ¢æ•°æ®```bash

â”‚   â”œâ”€â”€ MOT/ / SOT/                 # æ ‡å‡†æ•°æ®é›†

â”‚   â”œâ”€â”€ MultiUAV_Test/ / MultiUAV_Train/python test_uavswarm.py

â”‚   â””â”€â”€ UAVSwarm-dataset-master/    # åŸå§‹ UAVSwarm æ•°æ®

â”‚```

â”œâ”€â”€ test_results/

â”‚   â”œâ”€â”€ UAVSwarm-02/ / UAVSwarm-12/ / UAVSwarm-44/**è¾“å‡ºç¤ºä¾‹**ï¼š  - æŒ‰åºåˆ—å¤„ç†å¹¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚

â”‚   â”œâ”€â”€ UAVSwarm-*_bytetrack/       # ByteTrack ç»“æœ

â”‚   â””â”€â”€ UAVSwarm-*_tracking/        # BoT-SORT ç»“æœ### è¾“å‡ºè¯´æ˜

â”‚

â”œâ”€â”€ TrackEval/```

â”‚   â”œâ”€â”€ trackeval/

â”‚   â”‚   â”œâ”€â”€ metrics/                # è¯„ä¼°æŒ‡æ ‡- **detections.txt**ï¼šMOT æ ¼å¼çš„æ£€æµ‹ç»“æœæ–‡ä»¶

â”‚   â”‚   â”‚   â”œâ”€â”€ hota.py             # HOTAï¼ˆæ¨èï¼‰

â”‚   â”‚   â”‚   â”œâ”€â”€ clear.py            # MOTA/MOTP- **vis_*.jpg**ï¼šå¯è§†åŒ–å›¾åƒï¼Œä¾¿äºæŸ¥çœ‹æ£€æµ‹æ•ˆæœuav_custom/- **è¿è¡Œ**:  python convert_labelme_to_yolo.py<a href="https://github.com/wish44165/wish44165/tree/main/assets"><img src="https://github.com/wish44165/wish44165/blob/main/assets/msi_Cyborg_15_A12VE_badge.svg" alt="MSI"></a> 

â”‚   â”‚   â”‚   â”œâ”€â”€ identity.py         # IDF1

â”‚   â”‚   â”‚   â””â”€â”€ track_map.py        # Track mAP

â”‚   â”‚   â”œâ”€â”€ datasets/               # æ•°æ®é›†åŠ è½½å™¨

â”‚   â”‚   â”œâ”€â”€ eval.py                 # è¯„ä¼°ä¸»ç¨‹åº**detections.txt æ ¼å¼**ï¼šâ”œâ”€â”€ images/

â”‚   â”‚   â””â”€â”€ plotting.py             # ç»“æœç»˜å›¾

â”‚   â”‚```

â”‚   â”œâ”€â”€ scripts/

â”‚   â”‚   â””â”€â”€ run_mot_challenge.py    # MOT è¯„ä¼°è„šæœ¬1,-1,123.5,98.2,45.0,52.1,0.95,-1,-1,-1â”‚   â”œâ”€â”€ train/  # è®­ç»ƒé›†å›¾ç‰‡ï¼ˆ70%ï¼‰  ```bash

â”‚   â”‚

â”‚   â”œâ”€â”€ data/1,-1,345.8,210.3,38.5,48.9,0.87,-1,-1,-1

â”‚   â”‚   â”œâ”€â”€ gt/                     # çœŸå®æ ‡æ³¨

â”‚   â”‚   â””â”€â”€ trackers/               # è·Ÿè¸ªç»“æœ2,-1,125.3,100.1,44.5,51.8,0.92,-1,-1,-1â”‚   â””â”€â”€ val/    # éªŒè¯é›†å›¾ç‰‡ï¼ˆ30%ï¼‰

â”‚   â”‚

â”‚   â”œâ”€â”€ docs/                       # æ–‡æ¡£```

â”‚   â””â”€â”€ requirements.txt

â”‚â””â”€â”€ labels/  python convert_uavswarm_to_yolo.py  ```<a href="https://dashboard.hpc.unimelb.edu.au/"><img src="https://github.com/wish44165/wish44165/blob/main/assets/unimelb_spartan.svg" alt="Spartan"></a> 

â”œâ”€â”€ convert_labelme_to_yolo.py      # LabelMe è½¬æ¢å·¥å…·

â”œâ”€â”€ convert_uavswarm_to_yolo.py     # UAVSwarm è½¬æ¢å·¥å…·---

â”œâ”€â”€ test_uavswarm.py                # æ¨ç†æ£€æµ‹å·¥å…·

â”œâ”€â”€ evaluate_detections.py          # è¯„ä¼°å·¥å…·    â”œâ”€â”€ train/  # è®­ç»ƒé›†æ ‡ç­¾

â””â”€â”€ README.md                       # æœ¬æ–‡æ¡£

```## ğŸ“Š ç»“æœè¯„ä¼°



---    â””â”€â”€ val/    # éªŒè¯é›†æ ‡ç­¾  ```



## ğŸ’» ä½¿ç”¨æµç¨‹ç¤ºä¾‹**è„šæœ¬**ï¼š`evaluate_detections.py`



### æµç¨‹ 1ï¼šä½¿ç”¨è‡ªå®šä¹‰ LabelMe æ ‡æ³¨æ•°æ®```



```bash### åŠŸèƒ½è¯´æ˜

# 1. è½¬æ¢æ ‡æ³¨æ ¼å¼

python convert_labelme_to_yolo.py  *æ³¨æ„ï¼šéœ€åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `base_dir` ä¸ºæ•°æ®é›†æ ¹ç›®å½•ã€‚*



# 2. ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è®­ç»ƒæ¨¡å‹å¯¹æ¯”é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼Œè®¡ç®—æ£€æµ‹ç²¾åº¦æŒ‡æ ‡ï¼š

cd BoT-SORT/yolov12/

python train.py --yaml_path ../../../uav_custom.yaml --n_epoch 100---



# 3. ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¨ç†1. **è§£ææ–‡ä»¶**ï¼šè¯»å–é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼ˆéƒ½æ˜¯ MOT æ ¼å¼ï¼‰

cd ../../..

python test_uavswarm.py2. **IOU åŒ¹é…**ï¼šè®¡ç®—é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„äº¤å¹¶æ¯”



# 4. è¯„ä¼°æ£€æµ‹ç»“æœ3. **è®¡ç®—æŒ‡æ ‡**ï¼š

python evaluate_detections.py

```   - **TPï¼ˆçœŸæ­£ä¾‹ï¼‰**ï¼šIOU â‰¥ é˜ˆå€¼çš„æ­£ç¡®æ£€æµ‹### 2.2 UAVSwarm æ•°æ®é›†è½¬æ¢



### æµç¨‹ 2ï¼šä½¿ç”¨ UAVSwarm æ•°æ®é›†   - **FPï¼ˆå‡æ­£ä¾‹ï¼‰**ï¼šé”™è¯¯çš„æ£€æµ‹



```bash   - **FNï¼ˆå‡è´Ÿä¾‹ï¼‰**ï¼šæœªæ£€æµ‹åˆ°çš„ç›®æ ‡## 3. æ¨¡å‹æ¨ç†ä¸æ£€æµ‹- **UAVSwarm æ•°æ®é›†è½¬æ¢**:[![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)](https://medium.com/@scofield44165/ubuntu-24-04-1-getting-started-with-yolov12-bot-sort-reid-on-linux-20826ffc8224)

# 1. è½¬æ¢ MOT æ ¼å¼

python convert_uavswarm_to_yolo.py4. **ç”ŸæˆæŠ¥å‘Š**ï¼šè¾“å‡ºç²¾åº¦ã€å¬å›ç‡ã€F1 åˆ†æ•°ç­‰æŒ‡æ ‡



# 2. è®­ç»ƒæ¨¡å‹5. **é€å¸§å¯¹æ¯”**ï¼šéšæœºé‡‡æ ·æ˜¾ç¤ºéƒ¨åˆ†å¸§çš„è¯¦ç»†å¯¹æ¯”**åœºæ™¯**ï¼šä½ æœ‰ UAVSwarm æ•°æ®é›†ï¼ˆMOT Challenge æ ¼å¼ï¼‰ï¼ŒåŒ…å« `train/` å’Œ `test/` ç›®å½•ï¼Œæ¯ä¸ªåºåˆ—ä¸­æœ‰ `gt/gt.txt` å’Œ `img1/` æ–‡ä»¶å¤¹ã€‚

cd BoT-SORT/yolov12/

python train.py --yaml_path ../../../uavswarm.yaml



# 3. æ¨ç†### è®¡ç®—çš„æŒ‡æ ‡

cd ../../..

python test_uavswarm.py



# 4. è¯„ä¼°| æŒ‡æ ‡ | å…¬å¼ | è¯´æ˜ |**è„šæœ¬**ï¼š`convert_uavswarm_to_yolo.py`

python evaluate_detections.py

```|-----|------|------|



---| **Precision** | TP / (TP + FP) | æ£€æµ‹å‡†ç¡®ç‡ |ä½¿ç”¨è®­ç»ƒå¥½çš„ YOLOv12 æ¨¡å‹å¯¹å›¾åƒåºåˆ—è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚  é’ˆå¯¹ UAVSwarm æ•°æ®é›†ï¼Œä½¿ç”¨ `convert_uavswarm_to_yolo.py` å°†å…¶è½¬æ¢ä¸º YOLO è®­ç»ƒæ‰€éœ€çš„æ ¼å¼ã€‚[![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0)](https://medium.com/@scofield44165/macos-tahoe-26-0-1-getting-started-with-yolov12-bot-sort-reid-on-mac-f87400d5b096)



## ğŸ”§ TrackEval è¯„ä¼°å·¥å…·| **Recall** | TP / (TP + FN) | æ£€æµ‹å¬å›ç‡ |



ä½ç½®ï¼š`TrackEval/`| **F1-Score** | 2 Ã— P Ã— R / (P + R) | ç²¾åº¦å’Œå¬å›çš„è°ƒå’Œå¹³å‡æ•° |**åŠŸèƒ½**ï¼š



### æ”¯æŒçš„æŒ‡æ ‡| **Detection Rate** | TP / Total_GT | ç›®æ ‡æ£€æµ‹ç‡ |



- **HOTA**ï¼ˆæ¨èï¼‰ï¼šæ›´é«˜é˜¶çš„è·Ÿè¸ªç²¾åº¦| **False Alarm Rate** | FP / Total_Pred | è¯¯æ£€ç‡ |- è¯»å– MOT æ ¼å¼çš„ `gt.txt` æ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰å¸§çš„ç›®æ ‡æ ‡æ³¨ï¼‰

- **MOTA/MOTP**ï¼šå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦

- **IDF1**ï¼šèº«ä»½ä¿ç•™åº¦

- **Track mAP**ï¼šè·Ÿè¸ªå¹³å‡ç²¾åº¦

### ä½¿ç”¨æ–¹æ³•- **è¿‡æ»¤æœºåˆ¶**ï¼š

### ä½¿ç”¨ç¤ºä¾‹



```bash

cd TrackEval/ç¼–è¾‘è„šæœ¬ä¸­çš„æ–‡ä»¶è·¯å¾„ï¼š  - åªä¿ç•™å¯è§æ€§ (visibility) > 0.3 çš„ç›®æ ‡- **è„šæœ¬**: `test_uavswarm.py`  ```bash[![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)](https://medium.com/@scofield44165/windows-11-getting-started-with-yolov12-bot-sort-reid-on-windows-11-24ee1f1cd513)

python scripts/run_mot_challenge.py \

    --benchmark_name MOT17 \```python

    --split_to_eval test \

    --tracker_folder ../submit/track3/pred_file = r'D:\path\to\detections.txt'     # é¢„æµ‹ç»“æœ  - åªä¿ç•™ç½®ä¿¡åº¦ (conf) > 0 çš„ç›®æ ‡

```

gt_file = r'D:\path\to\gt.txt'               # çœŸå®æ ‡æ³¨

---

```- æŒ‰å¸§å· (frame_id) åˆ†ç»„ï¼Œä¸ºæ¯å¸§ç”Ÿæˆ YOLO æ ¼å¼çš„æ ‡ç­¾æ–‡ä»¶- **åŠŸèƒ½**:

## ğŸ“ å¸¸è§é—®é¢˜



### Q1ï¼šæ¨ç†æ—¶æç¤ºæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Ÿ

**A**ï¼šæ£€æŸ¥ `test_uavswarm.py` ä¸­çš„ `model_path` æ˜¯å¦æ­£ç¡®æŒ‡å‘ `.pt` æƒé‡æ–‡ä»¶ã€‚è¿è¡Œè¯„ä¼°ï¼š- è‡ªåŠ¨æ‰«æ `train/` å’Œ `test/` ç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰åºåˆ—



### Q2ï¼šè½¬æ¢æ•°æ®æ—¶æŠ¥é”™ "File not found"ï¼Ÿ```bash

**A**ï¼šç¡®ä¿è¾“å…¥è·¯å¾„ï¼ˆ`base_dir`ï¼‰å­˜åœ¨ï¼Œä¸”åŒ…å«ç›¸åº”æ ¼å¼çš„æ–‡ä»¶ï¼ˆJSON æˆ– gt.txtï¼‰ã€‚

python evaluate_detections.py- å°†æ‰€æœ‰åºåˆ—éšæœºåˆ†å‰²ä¸ºè®­ç»ƒé›†ï¼ˆ70%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ30%ï¼‰  - åŠ è½½ YOLOv12 æ¨¡å‹æƒé‡ã€‚  python convert_uavswarm_to_yolo.py[![ResearchGate](https://img.shields.io/badge/ResearchGate-00CCBB?style=for-the-badge&logo=ResearchGate&logoColor=white)](https://www.researchgate.net/publication/390114692_Strong_Baseline_Multi-UAV_Tracking_via_YOLOv12_with_BoT-SORT-ReID)

### Q3ï¼šè¯„ä¼°ç»“æœç²¾åº¦å¾ˆä½ï¼Ÿ

**A**ï¼šå¯èƒ½åŸå› ï¼š```

- æ¨¡å‹è®­ç»ƒä¸è¶³

- ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®è¿‡é«˜- ç”Ÿæˆ YOLO è®­ç»ƒæ‰€éœ€çš„ç»“æ„

- çœŸå®æ ‡æ³¨ä¸æ£€æµ‹æ¡†çš„ IOU ä¸åŒ¹é…

---

### Q4ï¼šå¦‚ä½•è°ƒæ•´æ£€æµ‹æ•æ„Ÿåº¦ï¼Ÿ

**A**ï¼šä¿®æ”¹ `test_uavswarm.py` ä¸­çš„ `conf_threshold`ï¼Œå€¼è¶Šä½è¶Šæ•æ„Ÿã€‚  - å¯¹æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å›¾ç‰‡è¿›è¡Œæ¨ç†ã€‚



### Q5ï¼šå¦‚ä½•ä½¿ç”¨ ReID è¿›è¡Œè·Ÿè¸ªï¼Ÿ## ğŸš€ æ ¸å¿ƒæ¨¡å—è¯´æ˜

**A**ï¼šåœ¨ `BoT-SORT/tools/predict_track3.py` ä¸­å¯ç”¨ `--with-reid` é€‰é¡¹ã€‚

**MOT æ ¼å¼è¯´æ˜**ï¼š

---

### BoT-SORT è·Ÿè¸ªå™¨

## ğŸ“š å‚è€ƒèµ„æº

```  - ç”Ÿæˆ MOT æ ¼å¼çš„æ£€æµ‹ç»“æœæ–‡ä»¶ `detections.txt`ã€‚  ```[![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@scofield44165/strong-baseline-multi-uav-tracking-via-yolov12-with-bot-sort-reid-5d6b71230e39)

- [YOLOv12](https://github.com/sunsmarterjie/yolov12) - æ£€æµ‹æ¨¡å‹

- [BoT-SORT](https://github.com/NirAharon/BoT-SORT) - è·Ÿè¸ªç®—æ³•ä½ç½®ï¼š`BoT-SORT/tracker/`

- [TrackEval](https://github.com/JonathonLuiten/TrackEval) - è¯„ä¼°å·¥å…·

- [MOT Challenge](https://motchallenge.net/) - å¤šç›®æ ‡è·Ÿè¸ªåŸºå‡†frame_id, track_id, x, y, w, h, conf, class_id, visibility

- [LabelMe](http://labelme.csail.mit.edu/) - æ ‡æ³¨å·¥å…·

**ä¸»è¦ç»„ä»¶**ï¼š

---

- **bot_sort.py**ï¼šæ ¸å¿ƒè·Ÿè¸ªç®—æ³•1,1,100,50,30,50,1,-1,0.9  - ä¿å­˜å¸¦æœ‰æ£€æµ‹æ¡†çš„å¯è§†åŒ–å›¾ç‰‡ã€‚

## ğŸ“„ License

  - ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢é¢„æµ‹è½¨è¿¹

æ­¤é¡¹ç›®ä»£ç éµå¾ªç›¸å…³å¼€æºé¡¹ç›®çš„è®¸å¯è¯ã€‚

  - æå–ç›®æ ‡å¤–è§‚ç‰¹å¾ï¼ˆReIDï¼‰```

---

  - è¿›è¡Œè½¨è¿¹åŒ¹é…

**æœ€åæ›´æ–°**ï¼š2025 å¹´ 11 æœˆ 25 æ—¥

  - **è¿è¡Œ**:[![YouTube](https://img.shields.io/badge/YouTube-%23FF0000.svg?style=for-the-badge&logo=YouTube&logoColor=white)](https://www.youtube.com/playlist?list=PLfr5E6mAx5EUpqP41CPSm5Nwfqe35iwtl)

- **kalman_filter.py**ï¼šå¡å°”æ›¼æ»¤æ³¢å™¨

  - é¢„æµ‹ç›®æ ‡ä½ç½®å’Œé€Ÿåº¦**YOLO è½¬æ¢**ï¼šåæ ‡è½¬æ¢ä¸ºå½’ä¸€åŒ–çš„ä¸­å¿ƒç‚¹å’Œå®½é«˜

  - å¤„ç†ç›®æ ‡è¿åŠ¨æ¨¡å‹

    ```bash

- **matching.py**ï¼šè½¨è¿¹åŒ¹é…ç®—æ³•

  - Hungarian ç®—æ³•è¿›è¡ŒäºŒéƒ¨å›¾åŒ¹é…**ä½¿ç”¨æ–¹æ³•**ï¼š

  - IOU ç›¸ä¼¼åº¦è®¡ç®—

  - ç‰¹å¾è·ç¦»è®¡ç®—  python test_uavswarm.py## 3. æ¨¡å‹æ¨ç†ä¸æµ‹è¯•



- **gmc.py**ï¼šå…¨å±€è¿åŠ¨è¡¥å¿ç¼–è¾‘è„šæœ¬ä¸­çš„è·¯å¾„ï¼š

  - å¤„ç†æ‘„åƒæœºè¿åŠ¨

  - æ”¹è¿›è½¨è¿¹çš„ç¨³å®šæ€§```python  ```



### YOLOv12 æ£€æµ‹æ¨¡å‹base_dir = r"D:\UAV\YOLOv12-BoT-SORT-ReID\data\UAVSwarm-dataset-master"  # æ•°æ®é›†æ ¹ç›®å½•



ä½ç½®ï¼š`BoT-SORT/yolov12/`output_train_imgs = r"..."    # è¾“å‡ºè®­ç»ƒé›†å›¾ç‰‡  *å‚æ•°é…ç½®ï¼ˆåœ¨è„šæœ¬ä¸­ä¿®æ”¹ï¼‰*:



**ä¸»è¦åŠŸèƒ½**ï¼šoutput_train_labels = r"..."  # è¾“å‡ºè®­ç»ƒé›†æ ‡ç­¾

- **train.py**ï¼šæ¨¡å‹è®­ç»ƒè„šæœ¬

  - ä»é¢„è®­ç»ƒæƒé‡å¼€å§‹è®­ç»ƒoutput_val_imgs = r"..."      # è¾“å‡ºéªŒè¯é›†å›¾ç‰‡  - `model_path`: æ¨¡å‹æƒé‡è·¯å¾„ (e.g., `best.pt`)

  - æ”¯æŒæ•°æ®å¢å¼º

  - è¾“å‡ºæ¨¡å‹æƒé‡å’Œæ—¥å¿—output_val_labels = r"..."    # è¾“å‡ºéªŒè¯é›†æ ‡ç­¾



- **é…ç½®æ–‡ä»¶**ï¼ˆYAMLï¼‰ï¼š```  - `image_folder`: å¾…æ£€æµ‹å›¾ç‰‡æ–‡ä»¶å¤¹ä½¿ç”¨ `test_uavswarm.py` å¯¹å›¾åƒåºåˆ—è¿›è¡Œæ¨ç†æµ‹è¯•ã€‚è¯¥è„šæœ¬ä¼šåŠ è½½è®­ç»ƒå¥½çš„ YOLOv12 æ¨¡å‹ï¼Œå¯¹æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹çš„å›¾ç‰‡è¿›è¡Œæ£€æµ‹ï¼Œå¹¶ä¿å­˜æ£€æµ‹ç»“æœå’Œå¯è§†åŒ–å›¾åƒã€‚

  - `uav.yaml`ï¼šé»˜è®¤ UAV æ•°æ®é›†é…ç½®

  - `uav_custom.yaml`ï¼šè‡ªå®šä¹‰ UAV æ•°æ®é›†é…ç½®

  - `uavswarm.yaml`ï¼šUAVSwarm æ•°æ®é›†é…ç½®

ç„¶åè¿è¡Œï¼š  - `output_folder`: ç»“æœä¿å­˜è·¯å¾„

**è®­ç»ƒå‘½ä»¤ç¤ºä¾‹**ï¼š

```bash```bash

cd BoT-SORT/yolov12/

python train.py --model_name weights/MOT_yolov12n.pt \python convert_uavswarm_to_yolo.py  - `conf_threshold`: ç½®ä¿¡åº¦é˜ˆå€¼

                 --yaml_path uav.yaml \

                 --n_epoch 100 \```

                 --bs 32 \

                 --imgsz 640

```

**è¾“å‡ºç¤ºä¾‹**ï¼š

### FastReID ç‰¹å¾æå–

```## 4. ç»“æœè¯„ä¼°```bash<details><summary>Preface</summary>

ä½ç½®ï¼š`BoT-SORT/fast_reid/`

uavswarm_yolo/

**åŠŸèƒ½**ï¼š

- æå–è¡Œäºº/æ— äººæœºå¤–è§‚ç‰¹å¾â”œâ”€â”€ images/

- ç”¨äºè½¨è¿¹å…³è”çš„ç‰¹å¾åŒ¹é…

- æ”¯æŒç‰¹å¾è·ç¦»è®¡ç®—â”‚   â”œâ”€â”€ train/  # æ‰€æœ‰åºåˆ—çš„è®­ç»ƒå›¾ç‰‡



**æ¥å£**ï¼š`fast_reid_interfece.py`â”‚   â””â”€â”€ val/    # æ‰€æœ‰åºåˆ—çš„éªŒè¯å›¾ç‰‡å¯¹æ£€æµ‹ç»“æœè¿›è¡Œå®šé‡è¯„ä¼°ï¼Œè®¡ç®—ç²¾åº¦æŒ‡æ ‡ã€‚python test_uavswarm.py

- åŠ è½½é¢„è®­ç»ƒæ¨¡å‹

- æå–è¾“å…¥å›¾åƒçš„ç‰¹å¾å‘é‡â””â”€â”€ labels/

- è®¡ç®—ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦

    â”œâ”€â”€ train/  # å¯¹åº”çš„è®­ç»ƒæ ‡ç­¾

---

    â””â”€â”€ val/    # å¯¹åº”çš„éªŒè¯æ ‡ç­¾

## ğŸ“ è¯¦ç»†æ–‡ä»¶ç»“æ„

```- **è„šæœ¬**: `evaluate_detections.py````The combination of YOLOv12 and BoT-SORT demonstrates strong object detection and tracking potential yet remains underexplored in current literature and implementations.

```

YOLOv12-BoT-SORT-ReID/

â”‚

â”œâ”€â”€ BoT-SORT/---- **åŠŸèƒ½**:

â”‚   â”œâ”€â”€ yolov12/

â”‚   â”‚   â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬

â”‚   â”‚   â”œâ”€â”€ weights/                   # æƒé‡æ–‡ä»¶

â”‚   â”‚   â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰## ğŸ” æ¨¡å‹æ¨ç†ä¸æ£€æµ‹  - è¯»å–é¢„æµ‹ç»“æœ (`detections.txt`) å’ŒçœŸå®æ ‡ç­¾ (`gt.txt`)ã€‚*æ³¨æ„ï¼šè¯·åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `model_path` å’Œ `image_folder` ä¸ºä½ çš„å®é™…è·¯å¾„ã€‚*

â”‚   â”‚   â”œâ”€â”€ ultralytics/               # Ultralytics æ¡†æ¶

â”‚   â”‚   â”œâ”€â”€ uav.yaml / uav_custom.yaml / uavswarm.yaml  # æ•°æ®é›†é…ç½®

â”‚   â”‚   â””â”€â”€ runs/                      # è®­ç»ƒè¾“å‡º

â”‚   â”‚**è„šæœ¬**ï¼š`test_uavswarm.py`  - è®¡ç®— **Precision**, **Recall**, **F1-Score**ã€‚

â”‚   â”œâ”€â”€ tracker/

â”‚   â”‚   â”œâ”€â”€ bot_sort.py                # æ ¸å¿ƒè·Ÿè¸ªç®—æ³•

â”‚   â”‚   â”œâ”€â”€ kalman_filter.py           # å¡å°”æ›¼æ»¤æ³¢å™¨

â”‚   â”‚   â”œâ”€â”€ matching.py                # è½¨è¿¹åŒ¹é…### åŠŸèƒ½è¯´æ˜  - è®¡ç®—æ£€æµ‹ç‡ (Detection Rate) å’Œè¯¯æ£€ç‡ (False Alarm Rate)ã€‚<img src="https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/assets/existing_methods_overview.png" width="100%">

â”‚   â”‚   â”œâ”€â”€ gmc.py                     # å…¨å±€è¿åŠ¨è¡¥å¿

â”‚   â”‚   â”œâ”€â”€ basetrack.py               # è½¨è¿¹åŸºç±»

â”‚   â”‚   â””â”€â”€ tracking_utils/            # å·¥å…·å‡½æ•°

â”‚   â”‚è¯¥è„šæœ¬ä½¿ç”¨å·²è®­ç»ƒçš„ YOLOv12 æ¨¡å‹å¯¹å›¾åƒåºåˆ—è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼š  - æ”¯æŒéšæœºé‡‡æ ·è¿›è¡Œé€å¸§ç»“æœå¯¹æ¯”ï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜ã€‚

â”‚   â”œâ”€â”€ fast_reid/

â”‚   â”‚   â”œâ”€â”€ fast_reid_interfece.py     # ReID æ¥å£

â”‚   â”‚   â”œâ”€â”€ fastreid/                  # æ¨¡å‹å®ç°

â”‚   â”‚   â”œâ”€â”€ projects/                  # é…ç½®æ–‡ä»¶1. **åŠ è½½æ¨¡å‹**ï¼šä» `.pt` æƒé‡æ–‡ä»¶åŠ è½½ YOLOv12 æ¨¡å‹- **è¿è¡Œ**:## 4. ç»“æœè¯„ä¼°

â”‚   â”‚   â””â”€â”€ logs/                      # é¢„è®­ç»ƒæ¨¡å‹

â”‚   â”‚2. **æ‰¹é‡æ¨ç†**ï¼šéå†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾åƒï¼ˆæ”¯æŒ .jpg, .jpeg, .png, .bmpï¼‰

â”‚   â”œâ”€â”€ tools/

â”‚   â”‚   â”œâ”€â”€ track.py                   # è·Ÿè¸ªä¸»ç¨‹åº3. **ç”Ÿæˆæ£€æµ‹ç»“æœ**ï¼š  ```bash

â”‚   â”‚   â”œâ”€â”€ predict_track1/2/3.py      # å„é˜¶æ®µæ¨ç†è„šæœ¬

â”‚   â”‚   â”œâ”€â”€ inference.py               # é€šç”¨æ¨ç†è„šæœ¬   - ä¿å­˜ä¸º **MOT æ ¼å¼** çš„ TXT æ–‡ä»¶ (`detections.txt`)

â”‚   â”‚   â”œâ”€â”€ mota.py / interpolation.py # æŒ‡æ ‡å’Œæ’å€¼

â”‚   â”‚   â””â”€â”€ demo.py                    # æ¼”ç¤ºè„šæœ¬   - æ¯è¡Œä¸€ä¸ªæ£€æµ‹æ¡†ï¼š`frame_id, -1, x, y, w, h, conf, -1, -1, -1`  python evaluate_detections.py```

â”‚   â”‚

â”‚   â”œâ”€â”€ tools/ â†’ datasets/4. **å¯è§†åŒ–**ï¼šåœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œç½®ä¿¡åº¦ï¼Œä¿å­˜ä¸º `vis_*.jpg`

â”‚   â”œâ”€â”€ cocoapi/                       # COCO API

â”‚   â”œâ”€â”€ datasets/                      # æ•°æ®é›†é…ç½®  ```

â”‚   â”œâ”€â”€ logs/                          # è®­ç»ƒæ—¥å¿—

â”‚   â”œâ”€â”€ runs/                          # æ¨ç†è¾“å‡º### ä½¿ç”¨æ–¹æ³•

â”‚   â”œâ”€â”€ submit/                        # æäº¤ç»“æœ

â”‚   â”œâ”€â”€ VideoCameraCorrection/         # æ‘„åƒæœºçŸ«æ­£  *å‚æ•°é…ç½®ï¼ˆåœ¨è„šæœ¬ä¸­ä¿®æ”¹ï¼‰*:ä½¿ç”¨ `evaluate_detections.py` å¯¹æ£€æµ‹ç»“æœè¿›è¡Œç²¾åº¦è¯„ä¼°ã€‚è¯¥è„šæœ¬ä¼šè®¡ç®— Precision, Recall, F1-Score ç­‰æŒ‡æ ‡ï¼Œå¹¶æ”¯æŒé€å¸§å¯¹æ¯”æŸ¥çœ‹ã€‚[1] Jocher, Glenn, et al. "ultralytics/yolov5: v6. 0-YOLOv5n'Nano'models, Roboflow integration, TensorFlow export, OpenCV DNN support." Zenodo (2021).

â”‚   â”œâ”€â”€ batch_process_videos.py        # æ‰¹å¤„ç†è„šæœ¬

â”‚   â”œâ”€â”€ getInfo.py                     # æ•°æ®ç»Ÿè®¡#### é…ç½®å‚æ•°

â”‚   â”œâ”€â”€ requirements.txt               # ä¾èµ–

â”‚   â””â”€â”€ run_track3.sh                  # è¿è¡Œè„šæœ¬  - `pred_file`: é¢„æµ‹ç”Ÿæˆçš„æ£€æµ‹æ–‡ä»¶è·¯å¾„

â”‚

â”œâ”€â”€ data/ç¼–è¾‘è„šæœ¬ä¸­çš„å‚æ•°ï¼š

â”‚   â”œâ”€â”€ images/                        # åŸå§‹å›¾åƒ

â”‚   â”œâ”€â”€ labels/                        # æ ‡æ³¨æ ‡ç­¾```python  - `gt_file`: çœŸå®æ ‡æ³¨æ–‡ä»¶è·¯å¾„[2] Tian, Yunjie, Qixiang Ye, and David Doermann. "Yolov12: Attention-centric real-time object detectors." arXiv preprint arXiv:2502.12524 (2025).

â”‚   â”œâ”€â”€ demo/                          # æ¼”ç¤ºæ•°æ®

â”‚   â”œâ”€â”€ uav_custom/                    # LabelMe è½¬æ¢æ•°æ®# æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆä½ è®­ç»ƒå¥½çš„æ¨¡å‹ï¼‰

â”‚   â”œâ”€â”€ uavswarm_yolo/                 # UAVSwarm è½¬æ¢æ•°æ®

â”‚   â”œâ”€â”€ MOT/ / SOT/                    # æ ‡å‡†æ•°æ®é›†model_path = r'D:\UAV\YOLOv12-BoT-SORT-ReID\BoT-SORT\yolov12\runs\uav\train15\weights\best.pt'

â”‚   â”œâ”€â”€ MultiUAV_Test/ / MultiUAV_Train/

â”‚   â””â”€â”€ UAVSwarm-dataset-master/       # åŸå§‹ UAVSwarm æ•°æ®

â”‚

â”œâ”€â”€ test_results/# è¾“å…¥ï¼šå¾…æ£€æµ‹çš„å›¾åƒæ–‡ä»¶å¤¹## 5. æ–‡ä»¶ç»“æ„è¯´æ˜```bash[3] Zhang, Guangdong, et al. "Multi-object Tracking Based on YOLOX and DeepSORT Algorithm." International Conference on 5G for Future Wireless Networks. Cham: Springer Nature Switzerland, 2022.

â”‚   â”œâ”€â”€ UAVSwarm-02/ / UAVSwarm-12/ / UAVSwarm-44/

â”‚   â”œâ”€â”€ UAVSwarm-*_bytetrack/          # ByteTrack ç»“æœimage_folder = r'D:\UAV\YOLOv12-BoT-SORT-ReID\data\UAVSwarm-dataset-master\test\UAVSwarm-44\img1'

â”‚   â””â”€â”€ UAVSwarm-*_tracking/           # BoT-SORT ç»“æœ

â”‚

â”œâ”€â”€ TrackEval/

â”‚   â”œâ”€â”€ trackeval/# è¾“å‡ºï¼šç»“æœä¿å­˜ç›®å½•

â”‚   â”‚   â”œâ”€â”€ metrics/                   # è¯„ä¼°æŒ‡æ ‡

â”‚   â”‚   â”‚   â”œâ”€â”€ hota.py                # HOTAï¼ˆæ¨èï¼‰output_folder = r'D:\UAV\YOLOv12-BoT-SORT-ReID\test_results\UAVSwarm-44'```python evaluate_detections.py[4] Aharon, Nir, Roy Orfaig, and Ben-Zion Bobrovsky. "Bot-sort: Robust associations multi-pedestrian tracking." arXiv preprint arXiv:2206.14651 (2022).

â”‚   â”‚   â”‚   â”œâ”€â”€ clear.py               # MOTA/MOTP

â”‚   â”‚   â”‚   â”œâ”€â”€ identity.py            # IDF1

â”‚   â”‚   â”‚   â””â”€â”€ track_map.py           # Track mAP

â”‚   â”‚   â”œâ”€â”€ datasets/                  # æ•°æ®é›†åŠ è½½å™¨# ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œè¶Šä½è¶Šæ•æ„ŸYOLOv12-BoT-SORT-ReID/

â”‚   â”‚   â”œâ”€â”€ eval.py                    # è¯„ä¼°ä¸»ç¨‹åº

â”‚   â”‚   â””â”€â”€ plotting.py                # ç»“æœç»˜å›¾conf_threshold = 0.3

â”‚   â”‚

â”‚   â”œâ”€â”€ scripts/```â”œâ”€â”€ BoT-SORT/                   # BoT-SORT ç®—æ³•åŠ YOLOv12 å­æ¨¡å—``````

â”‚   â”‚   â””â”€â”€ run_mot_challenge.py       # MOT è¯„ä¼°è„šæœ¬

â”‚   â”‚

â”‚   â”œâ”€â”€ data/

â”‚   â”‚   â”œâ”€â”€ gt/                        # çœŸå®æ ‡æ³¨#### è¿è¡Œæ¨ç†â”œâ”€â”€ data/                       # æ•°æ®é›†å­˜æ”¾ç›®å½•

â”‚   â”‚   â””â”€â”€ trackers/                  # è·Ÿè¸ªç»“æœ

â”‚   â”‚

â”‚   â”œâ”€â”€ docs/                          # æ–‡æ¡£

â”‚   â”‚   â””â”€â”€ MOTChallenge-format.txt    # MOT æ ¼å¼```bashâ”œâ”€â”€ test_results/               # æ¨ç†ç»“æœä¿å­˜ç›®å½•*æ³¨æ„ï¼šè¯·åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `pred_file` (é¢„æµ‹ç»“æœ) å’Œ `gt_file` (çœŸå®æ ‡ç­¾) çš„è·¯å¾„ã€‚*

â”‚   â”‚

â”‚   â””â”€â”€ requirements.txt               # ä¾èµ–python test_uavswarm.py

â”‚

â”œâ”€â”€ convert_labelme_to_yolo.py         # LabelMe è½¬æ¢å·¥å…·```â”œâ”€â”€ TrackEval/                  # è·Ÿè¸ªè¯„æµ‹å·¥å…·åº“

â”œâ”€â”€ convert_uavswarm_to_yolo.py        # UAVSwarm è½¬æ¢å·¥å…·

â”œâ”€â”€ test_uavswarm.py                   # æ¨ç†æ£€æµ‹å·¥å…·

â”œâ”€â”€ evaluate_detections.py             # è¯„ä¼°å·¥å…·

â””â”€â”€ README.md                          # æœ¬æ–‡æ¡£#### è¾“å‡ºè¯´æ˜â”œâ”€â”€ convert_labelme_to_yolo.py  # [å·¥å…·] LabelMe -> YOLO è½¬æ¢</details>

```



---

è„šæœ¬ä¼šè¾“å‡ºï¼šâ”œâ”€â”€ convert_uavswarm_to_yolo.py # [å·¥å…·] UAVSwarm -> YOLO è½¬æ¢

## ğŸ’» ä½¿ç”¨æµç¨‹ç¤ºä¾‹

- **detections.txt**ï¼šMOT æ ¼å¼çš„æ£€æµ‹ç»“æœæ–‡ä»¶ï¼Œå¯ç”¨äºåç»­è¯„ä¼°

### æµç¨‹ 1ï¼šä½¿ç”¨è‡ªå®šä¹‰ LabelMe æ ‡æ³¨æ•°æ®

- **vis_*.jpg**ï¼šå¯è§†åŒ–å›¾åƒï¼Œä¾¿äºæŸ¥çœ‹æ£€æµ‹æ•ˆæœâ”œâ”€â”€ evaluate_detections.py      # [å·¥å…·] æ£€æµ‹ç»“æœè¯„ä¼°## 5. æ–‡ä»¶ç»“æ„è¯´æ˜

```bash

# 1. è½¬æ¢æ ‡æ³¨æ ¼å¼

python convert_labelme_to_yolo.py

**ç¤ºä¾‹è¾“å‡º**ï¼šâ”œâ”€â”€ test_uavswarm.py            # [å·¥å…·] æ¨¡å‹æ¨ç†æµ‹è¯•

# 2. ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è®­ç»ƒæ¨¡å‹

cd BoT-SORT/yolov12/```

python train.py --yaml_path ../../../uav_custom.yaml --n_epoch 100

test_results/UAVSwarm-44/â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£

# 3. ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¨ç†

cd ../../..â”œâ”€â”€ detections.txt         # æ£€æµ‹ç»“æœ

python test_uavswarm.py

â”œâ”€â”€ vis_000001.jpg         # å¯è§†åŒ–ç»“æœ```

# 4. è¯„ä¼°æ£€æµ‹ç»“æœ

python evaluate_detections.pyâ”œâ”€â”€ vis_000002.jpg

```

â”œâ”€â”€ ...```

### æµç¨‹ 2ï¼šä½¿ç”¨ UAVSwarm æ•°æ®é›†

â””â”€â”€ vis_000100.jpg

```bash

# 1. è½¬æ¢ MOT æ ¼å¼```## 6. å‚è€ƒå¼•ç”¨

python convert_uavswarm_to_yolo.py



# 2. è®­ç»ƒæ¨¡å‹

cd BoT-SORT/yolov12/**detections.txt æ ¼å¼**ï¼šYOLOv12-BoT-SORT-ReID/

python train.py --yaml_path ../../../uavswarm.yaml

```

# 3. æ¨ç†

cd ../../..1,-1,123.5,98.2,45.0,52.1,0.95,-1,-1,-1æœ¬é¡¹ç›®å‚è€ƒäº†ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼š

python test_uavswarm.py

1,-1,345.8,210.3,38.5,48.9,0.87,-1,-1,-1

# 4. è¯„ä¼°

python evaluate_detections.py2,-1,125.3,100.1,44.5,51.8,0.92,-1,-1,-1- [YOLOv12](https://github.com/sunsmarterjie/yolov12)â”œâ”€â”€ BoT-SORT/               # BoT-SORT è·Ÿè¸ªç®—æ³•æ ¸å¿ƒä»£ç This repository provides a strong baseline for multi-UAV tracking in thermal infrared videos by leveraging YOLOv12 and BoT-SORT with ReID. Our approach significantly outperforms the widely adopted YOLOv5 with the DeepSORT pipeline, offering a high-performance foundation for UAV swarm tracking. Importantly, the established workflow in this repository can be easily integrated with any custom-trained model, extending its applicability beyond UAV scenarios. Refer to [this](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID#-quickstart-installation-and-demonstration) section for practical usage examples.

```

...

---

```- [BoT-SORT](https://github.com/NirAharon/BoT-SORT)

## ğŸ”§ TrackEval è¯„ä¼°å·¥å…·



ä½ç½®ï¼š`TrackEval/`

---â”œâ”€â”€ data/                   # æ•°æ®é›†ç›®å½•

### æ”¯æŒçš„æŒ‡æ ‡



- **HOTA**ï¼ˆæ¨èï¼‰ï¼šæ›´é«˜é˜¶çš„è·Ÿè¸ªç²¾åº¦

- **MOTA/MOTP**ï¼šå¤šç›®æ ‡è·Ÿè¸ªç²¾åº¦## ğŸ“Š ç»“æœè¯„ä¼°â”œâ”€â”€ test_results/           # æµ‹è¯•ç»“æœä¿å­˜ç›®å½•

- **IDF1**ï¼šèº«ä»½ä¿ç•™åº¦

- **Track mAP**ï¼šè·Ÿè¸ªå¹³å‡ç²¾åº¦



### ä½¿ç”¨ç¤ºä¾‹**è„šæœ¬**ï¼š`evaluate_detections.py`â”œâ”€â”€ TrackEval/              # è¯„æµ‹å·¥å…·



```bash

cd TrackEval/

python scripts/run_mot_challenge.py \### åŠŸèƒ½è¯´æ˜â”œâ”€â”€ convert_labelme_to_yolo.py  # LabelMe æ ¼å¼è½¬æ¢è„šæœ¬

    --benchmark_name MOT17 \

    --split_to_eval test \

    --tracker_folder ../submit/track3/

```è¯¥è„šæœ¬å¯¹æ¯”é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼Œè®¡ç®—æ£€æµ‹ç²¾åº¦æŒ‡æ ‡ï¼šâ”œâ”€â”€ convert_uavswarm_to_yolo.py # UAVSwarm æ•°æ®é›†è½¬æ¢è„šæœ¬<details><summary>ğŸ“¹ Preview - Strong Baseline</summary>



### è¾“å‡º



è‡ªåŠ¨ç”Ÿæˆï¼š1. **è§£ææ–‡ä»¶**ï¼šè¯»å–é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾ï¼ˆéƒ½æ˜¯ MOT æ ¼å¼ï¼‰â”œâ”€â”€ evaluate_detections.py      # æ£€æµ‹ç»“æœè¯„ä¼°è„šæœ¬

- è¯¦ç»†çš„ CSV ç»“æœæ–‡ä»¶

- å¯è§†åŒ–å›¾è¡¨2. **IOU åŒ¹é…**ï¼šè®¡ç®—é¢„æµ‹æ¡†å’ŒçœŸå®æ¡†çš„äº¤å¹¶æ¯” (Intersection over Union)

- æ±‡æ€»æŠ¥å‘Š

3. **è®¡ç®—æŒ‡æ ‡**ï¼šâ”œâ”€â”€ test_uavswarm.py            # æ¨ç†æµ‹è¯•è„šæœ¬[strong_baseline.webm](https://github.com/user-attachments/assets/702b3e80-fd3c-48f0-8032-a2a97563c19f)

---

   - **TPï¼ˆçœŸæ­£ä¾‹ï¼‰**ï¼šIOU â‰¥ é˜ˆå€¼çš„æ­£ç¡®æ£€æµ‹

## ğŸ“ å¸¸è§é—®é¢˜

   - **FPï¼ˆå‡æ­£ä¾‹ï¼‰**ï¼šé”™è¯¯çš„æ£€æµ‹æˆ–ä½äºé˜ˆå€¼çš„æ£€æµ‹â””â”€â”€ README.md                   # é¡¹ç›®è¯´æ˜æ–‡æ¡£

### Q1ï¼šæ¨ç†æ—¶æç¤ºæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Ÿ

**A**ï¼šæ£€æŸ¥ `test_uavswarm.py` ä¸­çš„ `model_path` æ˜¯å¦æ­£ç¡®æŒ‡å‘ `.pt` æƒé‡æ–‡ä»¶ã€‚   - **FNï¼ˆå‡è´Ÿä¾‹ï¼‰**ï¼šæœªæ£€æµ‹åˆ°çš„ç›®æ ‡



### Q2ï¼šè½¬æ¢æ•°æ®æ—¶æŠ¥é”™ "File not found"ï¼Ÿ4. **ç”ŸæˆæŠ¥å‘Š**ï¼šè¾“å‡ºç²¾åº¦ã€å¬å›ç‡ã€F1 åˆ†æ•°ç­‰æŒ‡æ ‡```ğŸ”— Full video available at: [Track 3](https://youtu.be/_IiUISzCeU8?si=19JnHdwS9GLoYdtL)

**A**ï¼šç¡®ä¿è¾“å…¥è·¯å¾„ï¼ˆ`base_dir`ï¼‰å­˜åœ¨ï¼Œä¸”åŒ…å«ç›¸åº”æ ¼å¼çš„æ–‡ä»¶ï¼ˆJSON æˆ– gt.txtï¼‰ã€‚

5. **é€å¸§å¯¹æ¯”**ï¼šéšæœºé‡‡æ ·æ˜¾ç¤ºéƒ¨åˆ†å¸§çš„è¯¦ç»†å¯¹æ¯”

### Q3ï¼šè¯„ä¼°ç»“æœç²¾åº¦å¾ˆä½ï¼Ÿ

**A**ï¼šå¯èƒ½åŸå› ï¼š

- æ¨¡å‹è®­ç»ƒä¸è¶³

- ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®è¿‡é«˜### è®¡ç®—çš„æŒ‡æ ‡

- çœŸå®æ ‡æ³¨ä¸æ£€æµ‹æ¡†çš„ IOU ä¸åŒ¹é…

## 6. å‚è€ƒå¼•ç”¨ğŸ” See also SOT inferences: [Track 1](https://youtu.be/HOwMRm1l124?si=ewlZ5wr1_CUDFWk_) and [Track 2](https://youtu.be/M7lSrqYkpEQ?si=EyVhfOPNRLPVzYI2)

### Q4ï¼šå¦‚ä½•è°ƒæ•´æ£€æµ‹æ•æ„Ÿåº¦ï¼Ÿ

**A**ï¼šä¿®æ”¹ `test_uavswarm.py` ä¸­çš„ `conf_threshold`ï¼Œå€¼è¶Šä½è¶Šæ•æ„Ÿã€‚| æŒ‡æ ‡ | å…¬å¼ | è¯´æ˜ |



### Q5ï¼šå¦‚ä½•ä½¿ç”¨ ReID è¿›è¡Œè·Ÿè¸ªï¼Ÿ|-----|------|------|

**A**ï¼šåœ¨ `BoT-SORT/tools/predict_track3.py` ä¸­å¯ç”¨ `--with-reid` é€‰é¡¹ã€‚

| **Precision** | TP / (TP + FP) | æ£€æµ‹å‡†ç¡®ç‡ï¼šæ­£ç¡®æ£€æµ‹çš„æ¯”ä¾‹ |

---

| **Recall** | TP / (TP + FN) | æ£€æµ‹å¬å›ç‡ï¼šæ£€æµ‹åˆ°çš„ç›®æ ‡æ¯”ä¾‹ |æœ¬é¡¹ç›®å‚è€ƒäº†ä»¥ä¸‹å¼€æºé¡¹ç›®ï¼šğŸŒ [CVPR2025](https://cvpr.thecvf.com/) | [Workshops](https://cvpr.thecvf.com/Conferences/2025/workshop-list) | [4th Anti-UAV Workshop](https://anti-uav.github.io/) | [Track-1](https://codalab.lisn.upsaclay.fr/competitions/21688) | [Track-2](https://codalab.lisn.upsaclay.fr/competitions/21690) | [Track-3](https://codalab.lisn.upsaclay.fr/competitions/21806)

## ğŸ“š å‚è€ƒèµ„æº

| **F1-Score** | 2 Ã— P Ã— R / (P + R) | ç²¾åº¦å’Œå¬å›çš„è°ƒå’Œå¹³å‡æ•° |

- [YOLOv12](https://github.com/sunsmarterjie/yolov12) - æ£€æµ‹æ¨¡å‹

- [BoT-SORT](https://github.com/NirAharon/BoT-SORT) - è·Ÿè¸ªç®—æ³•| **Detection Rate** | TP / Total_GT | ç›®æ ‡æ£€æµ‹ç‡ |- [YOLOv12](https://github.com/sunsmarterjie/yolov12)

- [TrackEval](https://github.com/JonathonLuiten/TrackEval) - è¯„ä¼°å·¥å…·

- [MOT Challenge](https://motchallenge.net/) - å¤šç›®æ ‡è·Ÿè¸ªåŸºå‡†| **False Alarm Rate** | FP / Total_Pred | è¯¯æ£€ç‡ |

- [LabelMe](http://labelme.csail.mit.edu/) - æ ‡æ³¨å·¥å…·

- [BoT-SORT](https://github.com/NirAharon/BoT-SORT)</details>

---

### ä½¿ç”¨æ–¹æ³•

## ğŸ“„ License

- [TrackEval](https://github.com/JonathonLuiten/TrackEval)

æ­¤é¡¹ç›®ä»£ç éµå¾ªç›¸å…³å¼€æºé¡¹ç›®çš„è®¸å¯è¯ã€‚

#### é…ç½®å‚æ•°

---



**æœ€åæ›´æ–°**ï¼š2025 å¹´ 11 æœˆ 25 æ—¥

ç¼–è¾‘è„šæœ¬ä¸­çš„æ–‡ä»¶è·¯å¾„ï¼š

```python

# é¢„æµ‹ç»“æœï¼ˆä» test_uavswarm.py ç”Ÿæˆï¼‰<details><summary>ğŸ“¹ Preview - Single-Frame Enhancements</summary>

pred_file = r'D:\UAV\YOLOv12-BoT-SORT-ReID\test_results\UAVSwarm-44\detections.txt'

[enhancements_MultiUAV-261.webm](https://github.com/user-attachments/assets/f1dd3877-d898-45c2-93c9-26f677020e07)

# çœŸå®æ ‡æ³¨ï¼ˆæ•°æ®é›†è‡ªå¸¦ï¼‰

gt_file = r'D:\UAV\YOLOv12-BoT-SORT-ReID\data\UAVSwarm-dataset-master\test\UAVSwarm-44\det\det.txt'ğŸ”— Full video available at: [Enhancements](https://youtu.be/lkIlYCjz8r4?si=7jpgs5OAEeABNVGo)

```

</details>

#### è¿è¡Œè¯„ä¼°



```bash

python evaluate_detections.py

```<details><summary>ğŸ“¹ Preview - Custom Model Inference</summary>



#### è¾“å‡ºç¤ºä¾‹This section showcases example videos processed using a custom-trained model. The scenes are not limited to UAV footage or single-class detection. See [ğŸš€ Quickstart: Installation and Demonstration](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID?tab=readme-ov-file#-quickstart-installation-and-demonstration) â†’ `Run Inference Using a Custom-Trained Model` for more details.



```<details><summary>1. Multi-Class on a Walkway Scene</summary>

============================================================

ğŸ“Š DETECTION EVALUATION[palace.webm](https://github.com/user-attachments/assets/cc32bda1-f461-4813-9639-eab2adfc178e)

============================================================

ğŸ”— Original video: [palace.mp4](https://github.com/FoundationVision/ByteTrack/blob/main/videos/palace.mp4)

ğŸ“ Prediction file: ...

   Total frames: 1200</details>

   Total detections: 3456

<details><summary>2. Common Objects Underwater</summary>

ğŸ“ Ground truth file: ...

   Total frames: 1200[cou.webm](https://github.com/user-attachments/assets/59a81337-245a-49a7-817e-422536199b19)

   Total ground truth boxes: 3520

ğŸ”— Full video available at: [COU.mp4](https://youtu.be/dZAQnpDq7NQ?si=ovF637bp4D-HZ04_)

ğŸ“ˆ Total frames to evaluate: 1200

</details>

------------------------------------------------------------

ğŸ“Š METRICS (IOU threshold: 0.5)<details><summary>3. UAVDB</summary>

------------------------------------------------------------

True Positives (TP):   3250[uavdb.webm](https://github.com/user-attachments/assets/3eff3e71-4111-4792-b4f6-4f1371843978)

False Positives (FP):  206

False Negatives (FN):  270ğŸ”— Full video available at: [UAVDB.mp4](https://youtu.be/NOZ4yhgXF7Q?si=bPM0N3SjR6tcHH3z)



Precision: 0.9406 (3250/3456)</details>

Recall:    0.9232 (3250/3520)

F1-Score:  0.9318<details open><summary>4. NPS-Drones dataset</summary>



Detection Rate: 92.32% (3250/3520)[nps.webm](https://github.com/user-attachments/assets/78209701-f61d-480b-9bb4-c0e8697d6148)

False Alarm Rate: 5.96% (206/3456)

ğŸ”— Full video available at: [NPS.mp4](https://youtu.be/a5jTaHiARkE?si=mIBWeIPpI1IMGF6O)

============================================================

ğŸ” FRAME-BY-FRAME COMPARISON</details>

============================================================

</details>

æ˜¾ç¤º 15 ä¸ªæ ·æœ¬å¸§çš„å¯¹æ¯”:



Frame 000001:

  Predictions: 3 boxes

  Ground Truth: 3 boxes

  âœ… Count matches



Frame 000002:

  Predictions: 2 boxes## ğŸ Beyond Strong Baseline: Multi-UAV Tracking Competition â‚ŠËšâŠ¹

  Ground Truth: 3 boxes

  âš ï¸  Count mismatch: 2 vs 3

  

...

```<details><summary>ğŸ“¹ Preview - Vision in Action: Overview of All Videos</summary>



---A complete visual overview of all training and test videos.



## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„[vision_in_action.webm](https://github.com/user-attachments/assets/f50d8e90-63b8-4b62-84ca-7e71c0750c67)



```ğŸ”— Full video available at: [Overview](https://youtu.be/0-Sn_mxRPJw?si=xfFXvBNoQz8zxnbK)

YOLOv12-BoT-SORT-ReID/

â”‚Scenarios are categorized to evaluate tracking performance under diverse conditions:

â”œâ”€â”€ BoT-SORT/                          # BoT-SORT ç®—æ³•å’Œ YOLOv12 å­æ¨¡å—

â”‚   â”œâ”€â”€ yolov12/                       # YOLOv12 æ£€æµ‹æ¨¡å‹- **Takeoff** - UAV launch phase: 2 videos.

â”‚   â”‚   â”œâ”€â”€ train.py                   # æ¨¡å‹è®­ç»ƒè„šæœ¬- **L** - Larger UAV target: 15 videos.

â”‚   â”‚   â”œâ”€â”€ weights/                   # é¢„è®­ç»ƒæƒé‡- **C** - Cloud background: 39 videos.

â”‚   â”‚   â””â”€â”€ requirements.txt           # ä¾èµ–- **CF** - Cloud (Fewer UAVs): 18 videos.

â”‚   â”œâ”€â”€ tracker/                       # BoT-SORT è·Ÿè¸ªå™¨å®ç°- **T** - Tree background: 68 videos.

â”‚   â”œâ”€â”€ fast_reid/                     # ReID ç‰¹å¾æå–æ¨¡å—- **TF** - Tree (Fewer UAVs): 14 videos.

â”‚   â””â”€â”€ requirements.txt               # ç¯å¢ƒä¾èµ–- **B** - Scene with buildings: 11 videos.

â”‚- **BB1** - Building Background 1: 4 videos.

â”œâ”€â”€ data/                              # æ•°æ®å­˜æ”¾ç›®å½•- **BB2** - Building Background 2: 17 videos.

â”‚   â”œâ”€â”€ images/                        # åŸå§‹å›¾åƒï¼ˆæŒ‰æ—¥æœŸåˆ†ç±»ï¼‰- **BB2P** - Building Background 2 (UAV partially out of view): 8 videos.

â”‚   â”œâ”€â”€ labels/                        # æ ‡æ³¨æ ‡ç­¾- **Landing** - UAV landing phase: 4 videos.

â”‚   â”œâ”€â”€ uav_custom/                    # LabelMe è½¬æ¢åçš„æ•°æ®ï¼ˆYOLOæ ¼å¼ï¼‰

â”‚   â”œâ”€â”€ uavswarm_yolo/                 # UAVSwarm è½¬æ¢åçš„æ•°æ®ï¼ˆYOLOæ ¼å¼ï¼‰**TOTAL: 200 videos (151,384 frames)**

â”‚   â”œâ”€â”€ MOT/                           # MOT æ•°æ®é›†

â”‚   â”œâ”€â”€ SOT/                           # SOT æ•°æ®é›†</details>

â”‚   â””â”€â”€ UAVSwarm-dataset-master/       # UAVSwarm åŸå§‹æ•°æ®é›†

â”‚

â”œâ”€â”€ test_results/                      # æ¨ç†ç»“æœä¿å­˜ç›®å½•

â”‚   â”œâ”€â”€ UAVSwarm-02/

â”‚   â”œâ”€â”€ UAVSwarm-12/<details><summary>ğŸ“¹ Preview - Vision in Action: Training Videos</summary>

â”‚   â””â”€â”€ UAVSwarm-44/

â”‚[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15853476.svg)](https://doi.org/10.5281/zenodo.15853476)

â”œâ”€â”€ TrackEval/                         # è·Ÿè¸ªè¯„ä¼°å·¥å…·åº“

â”œâ”€â”€ convert_labelme_to_yolo.py         # [å·¥å…·] LabelMe â†’ YOLO[demo_train.webm](https://github.com/user-attachments/assets/e01c0bb5-f08e-4a76-829f-7d2ea717184e)

â”œâ”€â”€ convert_uavswarm_to_yolo.py        # [å·¥å…·] UAVSwarm MOT â†’ YOLO

â”œâ”€â”€ test_uavswarm.py                   # [å·¥å…·] æ¨¡å‹æ¨ç†æ£€æµ‹ğŸ”— Full video available at: [Training Videos](https://youtu.be/rny0-nyFBk0?si=jxCPlCcHgU4zcUwU)

â”œâ”€â”€ evaluate_detections.py             # [å·¥å…·] æ£€æµ‹ç»“æœè¯„ä¼°

â””â”€â”€ README.md                          # é¡¹ç›®æ–‡æ¡£- **Takeoff** - UAV launch phase: 1 videos.

```- **L** - Larger UAV target: 8 videos.

- **C** - Cloud background: 20 videos.

---- **CF** - Cloud (Fewer UAVs): 9 videos.

- **T** - Tree background: 34 videos.

## ğŸš€ ä½¿ç”¨æµç¨‹ç¤ºä¾‹- **TF** - Tree (Fewer UAVs): 7 videos.

- **B** - Scene with buildings: 6 videos.

### åœºæ™¯ 1ï¼šä½¿ç”¨ LabelMe æ ‡æ³¨çš„è‡ªå®šä¹‰æ•°æ®- **BB1** - Building Background 1: 2 videos.

- **BB2** - Building Background 2: 9 videos.

```bash- **BB2P** - Building Background 2 (UAV partially out of view): 4 videos.

# 1. è½¬æ¢æ ‡æ³¨æ ¼å¼- **Landing** - UAV landing phase: 2 videos.

python convert_labelme_to_yolo.py

**TOTAL: 102 videos (77,293 frames)**

# 2. ä½¿ç”¨ç”Ÿæˆçš„ uav_custom æ•°æ®é›†è®­ç»ƒæ¨¡å‹

cd BoT-SORT/yolov12/</details>

python train.py  # éœ€è‡ªè¡Œé…ç½®è®­ç»ƒå‚æ•°



# 3. ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†

cd ../../

python test_uavswarm.py<details><summary>ğŸ“¹ Preview - Vision in Action: Test Videos</summary>



# 4. è¯„ä¼°æ£€æµ‹ç»“æœ[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.16299533.svg)](https://doi.org/10.5281/zenodo.16299533)

python evaluate_detections.py

```[demo_test.webm](https://github.com/user-attachments/assets/15e9143e-303f-4ef1-849d-735f8763e112)



### åœºæ™¯ 2ï¼šä½¿ç”¨ UAVSwarm æ•°æ®é›†ğŸ”— Full video available at: [Test Videos](https://youtu.be/G_8fE9njTRs?si=xUJjaYYC3D81m3Na)



```bash- **Takeoff** - UAV launch phase: 1 videos.

# 1. è½¬æ¢ MOT æ ¼å¼åˆ° YOLO æ ¼å¼- **L** - Larger UAV target: 7 videos.

python convert_uavswarm_to_yolo.py- **C** - Cloud background: 19 videos.

- **CF** - Cloud (Fewer UAVs): 9 videos.

# 2. ä½¿ç”¨ç”Ÿæˆçš„ uavswarm_yolo æ•°æ®é›†è®­ç»ƒæ¨¡å‹- **T** - Tree background: 34 videos.

cd BoT-SORT/yolov12/- **TF** - Tree (Fewer UAVs): 7 videos.

python train.py- **B** - Scene with buildings: 5 videos.

- **BB1** - Building Background 1: 2 videos.

# 3. å¯¹æµ‹è¯•é›†è¿›è¡Œæ¨ç†- **BB2** - Building Background 2: 8 videos.

cd ../../- **BB2P** - Building Background 2 (UAV partially out of view): 4 videos.

python test_uavswarm.py- **Landing** - UAV landing phase: 2 videos.



# 4. è¯„ä¼°æ¨ç†ç»“æœ**TOTAL: 98 videos (74,538 frames)**

python evaluate_detections.py

```</details>



---



## ğŸ“ å…³é”®ä»£ç è¯´æ˜

<details open><summary>ğŸ“¹ Preview - Vision in Action: Beyond Strong Baseline</summary>

### MOT æ ¼å¼

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.16458805.svg)](https://doi.org/10.5281/zenodo.16458805)

MOT Challenge æ ¼å¼æ˜¯å¤šç›®æ ‡è·Ÿè¸ªçš„æ ‡å‡†æ ¼å¼ï¼š

[<img src="https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/assets/beyond_strong_baseline.png" width="100%">](https://www.codabench.org/competitions/9888/)

```

frame_id, track_id, x, y, w, h, conf, class_id, visibility, [occlusion][<img src="https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/assets/beyond_strong_baseline_strong_baseline.png" width="100%">](https://www.codabench.org/competitions/9888/#/results-tab)

1, 1, 123.5, 98.2, 45.0, 52.1, 1, 1, 0.9, 0

2, 1, 125.3, 100.1, 44.5, 51.8, 1, 1, 0.95, 0ğŸ”— View the competition on [Codabench](https://www.codabench.org/competitions/9888/)

```

</details>

| å­—æ®µ | è¯´æ˜ | èŒƒå›´ |

|-----|------|------|

| frame_id | å¸§å· | æ­£æ•´æ•° |

| track_id | ç›®æ ‡ IDï¼ˆè·Ÿè¸ªæ—¶ä½¿ç”¨ï¼‰ | æ­£æ•´æ•° |

| x, y | è¾¹ç•Œæ¡†å·¦ä¸Šè§’åæ ‡ | åƒç´ åæ ‡ |### Participation

| w, h | è¾¹ç•Œæ¡†å®½é«˜ | åƒç´ åæ ‡ |

| conf | ç½®ä¿¡åº¦ | -1 (å¿½ç•¥) æˆ– 0-1 |<details><summary>Performance</summary>

| class_id | ç±»åˆ« ID | é€šå¸¸ä¸º 1ï¼ˆUAVç±»ï¼‰ |

| visibility | å¯è§åº¦ | 0-1 |[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.17089400.svg)](https://doi.org/10.5281/zenodo.17089400)



### YOLO æ ¼å¼[ViA_MultiUAV-261.webm](https://github.com/user-attachments/assets/dda89d21-7c25-4e33-b0cf-ab8fa126ac00)



YOLO ä½¿ç”¨å½’ä¸€åŒ–çš„ç›¸å¯¹åæ ‡ï¼šğŸ”— Full video available at: [Performance.mp4](https://youtu.be/uj-eFWOG9RU?si=BGWluZ9q2K1f0wwG)



```#### Public Leaderboard Phase

class_id x_center y_center width height

0 0.5 0.5 0.3 0.4| Methods                          | HOTA     | MOTA     | IDF1     |

```| :------------------------------: | :------: | :------: | :------: |

| Strong Baseline (SB)             | 0.873908 | 0.628351 | 0.717146 |

æ‰€æœ‰åæ ‡å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´å†…ï¼Œä¾¿äºæ¨¡å‹è®­ç»ƒã€‚| SB + CLAHE                       | 0.836414 | 0.626376 | 0.686967 |

| SB + Sobel-based Image Gradients | 0.823678 | 0.634651 | 0.680124 |

---| SB + Sobel-based Edge Sharpening | 0.831300 | 0.609124 | 0.680843 |

| [TransVisDrone](https://github.com/tusharsangam/TransVisDrone) | 0.818562 | 0.602384 | 0.683446 |

## ğŸ”§ å¸¸è§é—®é¢˜

</details>

### Q1ï¼šæ¨ç†æ—¶æç¤ºæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Ÿ

**A**ï¼šæ£€æŸ¥ `test_uavswarm.py` ä¸­çš„ `model_path` æ˜¯å¦æ­£ç¡®æŒ‡å‘ `.pt` æƒé‡æ–‡ä»¶ã€‚<details><summary>Interpolation</summary>



### Q2ï¼šè½¬æ¢æ•°æ®æ—¶æŠ¥é”™ "File not found"ï¼ŸInterpolation commands for this competition. Example usage:

**A**ï¼šç¡®ä¿è¾“å…¥è·¯å¾„ï¼ˆ`base_dir`ï¼‰å­˜åœ¨ï¼Œä¸”åŒ…å«ç›¸åº”æ ¼å¼çš„æ–‡ä»¶ï¼ˆJSON æˆ– gt.txtï¼‰ã€‚

```bash

### Q3ï¼šè¯„ä¼°ç»“æœç²¾åº¦å¾ˆä½ï¼Ÿ# input and output are both folders containing .txt files

**A**ï¼šå¯èƒ½åŸå› åŒ…æ‹¬ï¼š$ python tools/pre_interpolation.py --input ./submission --output ./pre_submission

- æ¨¡å‹è®­ç»ƒä¸è¶³$ python tools/interpolation.py --txt_path ./pre_submission --save_path ./mid_submission

- ç½®ä¿¡åº¦é˜ˆå€¼è®¾ç½®è¿‡é«˜$ python tools/post_interpolation.py --input ./mid_submission --output ./post_submission

- çœŸå®æ ‡æ³¨ä¸æ£€æµ‹æ¡†çš„ IOU è®¡ç®—æ–¹å¼ä¸åŒ¹é…```



### Q4ï¼šå¦‚ä½•è°ƒæ•´æ£€æµ‹æ•æ„Ÿåº¦ï¼Ÿ#### Public Leaderboard Phase

**A**ï¼šä¿®æ”¹ `test_uavswarm.py` ä¸­çš„ `conf_threshold` å‚æ•°ï¼Œå€¼è¶Šä½è¶Šæ•æ„Ÿã€‚

| Methods             | HOTA     | MOTA     | IDF1     |

---| :-----------------: | :------: | :------: | :------: |

| TransVisDrone (TVD) | 0.818562 | 0.602384 | 0.683446 |

## ğŸ“š å‚è€ƒèµ„æº| TVD + Interpolation | 0.832675 | 0.611150 | 0.689753 |



- [YOLOv12](https://github.com/sunsmarterjie/yolov12) - æ£€æµ‹æ¨¡å‹</details>

- [BoT-SORT](https://github.com/NirAharon/BoT-SORT) - è·Ÿè¸ªç®—æ³•

- [MOT Challenge](https://motchallenge.net/) - å¤šç›®æ ‡è·Ÿè¸ªåŸºå‡†

- [LabelMe](http://labelme.csail.mit.edu/) - æ ‡æ³¨å·¥å…·



---



## ğŸ“„ License



æ­¤é¡¹ç›®ä»£ç éµå¾ªç›¸å…³å¼€æºé¡¹ç›®çš„è®¸å¯è¯ã€‚## ğŸ—ï¸ News


## ğŸš€ Quickstart: Installation and Demonstration

[![Colab Notebook](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1x5T6woUdV6dD_T6qdYcKG04Q2iVVHGoD?usp=sharing)
[![Kaggle Notebook](https://img.shields.io/badge/Kaggle-Notebook-blue?logo=kaggle)](https://www.kaggle.com/code/yuhsi44165/yolov12-bot-sort/)

[![Linux](https://img.shields.io/badge/Linux-FCC624?style=for-the-badge&logo=linux&logoColor=black)](https://medium.com/@scofield44165/ubuntu-24-04-1-getting-started-with-yolov12-bot-sort-reid-on-linux-20826ffc8224)
[![macOS](https://img.shields.io/badge/mac%20os-000000?style=for-the-badge&logo=macos&logoColor=F0F0F0)](https://medium.com/@scofield44165/macos-tahoe-26-0-1-getting-started-with-yolov12-bot-sort-reid-on-mac-f87400d5b096)
[![Windows](https://img.shields.io/badge/Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white)](https://medium.com/@scofield44165/windows-11-getting-started-with-yolov12-bot-sort-reid-on-windows-11-24ee1f1cd513)

<details><summary>Installation</summary>

```bash
$ conda create -n yolov12_botsort python=3.11 -y
$ conda activate yolov12_botsort
$ git clone https://github.com/wish44165/YOLOv12-BoT-SORT-ReID.git
$ cd YOLOv12-BoT-SORT-ReID/BoT-SORT/yolov12/
$ wget https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.3/flash_attn-2.7.3+cu11torch2.2cxx11abiFALSE-cp311-cp311-linux_x86_64.whl
# Install dependencies (choose one):
$ pip install -r requirements.txt        # Linux
$ pip install -r requirements_mac.txt    # macOS
$ pip install -r requirements_win.txt    # Windows
$ cd ../
$ pip install torch torchvision torchaudio
$ pip install -r requirements.txt
$ pip install ultralytics
$ pip install cython; pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
$ pip install cython_bbox
$ pip install faiss-cpu
$ pip install seaborn
```

</details>


<details><summary>Folder Structure</summary>

The following folder structure will be created upon cloning this repository.

```
YOLOv12-BoT-SORT-ReID/
â”œâ”€â”€ data/
â”‚Â Â  â””â”€â”€ demo/
â”‚Â Â   Â Â  â”œâ”€â”€ MOT/
â”‚Â Â   Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-003.mp4
â”‚Â Â   Â Â  â”‚Â Â  â”œâ”€â”€ Test_imgs/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-003/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-135/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ MultiUAV-173/
â”‚Â Â   Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ MultiUAV-261/
â”‚Â Â   Â Â  â”‚Â Â  â””â”€â”€ TestLabels_FirstFrameOnly/
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-003.txt
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-135.txt
â”‚Â Â   Â Â  â”‚Â Â      â”œâ”€â”€ MultiUAV-173.txt
â”‚Â Â   Â Â  â”‚Â Â      â””â”€â”€ MultiUAV-261.txt
â”‚Â Â   Â Â  â””â”€â”€ SOT/
â”‚Â Â   Â Â      â”œâ”€â”€ Track1/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ 20190926_111509_1_8/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ 41_1/
â”‚Â Â   Â Â      â”‚Â Â  â”œâ”€â”€ new30_train-new/
â”‚Â Â   Â Â      â”‚Â Â  â””â”€â”€ wg2022_ir_050_split_01/
â”‚Â Â   Â Â      â””â”€â”€ Track2/
â”‚Â Â   Â Â          â”œâ”€â”€ 02_6319_0000-1499/
â”‚Â Â   Â Â          â”œâ”€â”€ 3700000000002_110743_1/
â”‚Â Â   Â Â          â”œâ”€â”€ DJI_0057_1/
â”‚Â Â   Â Â          â””â”€â”€ wg2022_ir_032_split_04/
â””â”€â”€ BoT-SORT/
```

</details>


<details><summary>Demonstration</summary>

Toy example with three tracks, including SOT and MOT.

```bash
$ cd BoT-SORT/

# Track 1
$ python tools/predict_track1.py --weights ./yolov12/weights/v1/SOT_yolov12l.pt --source ../data/demo/SOT/Track1/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 4 --save_path_answer ./submit/track1/demo --hide-labels-name
# output: ./runs/detect/, ./submit/track1/demo/

# Track 2
$ python tools/predict_track2.py --weights ./yolov12/weights/v1/SOT_yolov12l.pt --source ../data/demo/SOT/Track2/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 1 --save_path_answer ./submit/track2/demo --hide-labels-name
# output: ./runs/detect/, ./submit/track2/demo/

# Track 3
$ python tools/predict_track3.py --weights ./yolov12/weights/v1/MOT_yolov12n.pt --source ../data/demo/MOT/ --img-size 1600 --device "0" --track_buffer 60 --save_path_answer ./submit/track3/demo --hide-labels-name
$ python tools/predict_track3.py --weights ./yolov12/weights/v1/MOT_yolov12n.pt --source ../data/demo/MOT/ --img-size 1600 --device "0" --track_buffer 60 --save_path_answer ./submit/track3/demo --with-reid --fast-reid-config logs/sbs_S50/config.yaml --fast-reid-weights logs/sbs_S50/model_0016.pth --hide-labels-name
# output: ./runs/detect/, ./submit/track3/demo/

# Heatmap
$ cd yolov12/
$ python heatmap.py
# output: ./outputs/
```

</details>


<details><summary>Run Inference on Custom Data</summary>

This project supports flexible inference on image folders and video files, with or without initial object positions, specifically for MOT task.

```bash
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source <path to folder or video> \
    --with-initial-positions \
    --initial-position-config <path to initial positions file (optional)> \
    --img-size 1600 \
    --track_buffer 60 \
    --device "0" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/ \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --hide-labels-name
```

Below are examples of supported inference settings:

```bash
# 1. Inference on Image Folder (without initial position)
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source ../data/demo/MOT/Test_imgs/MultiUAV-003/ \
    --img-size 1600 \
    --track_buffer 60 \
    --device "0" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/ \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --hide-labels-name

# 2. Inference on Image Folder (with initial position)
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source ../data/demo/MOT/Test_imgs/MultiUAV-003/ \
    --with-initial-positions \
    --initial-position-config ../data/demo/MOT/TestLabels_FirstFrameOnly/MultiUAV-003.txt \
    --img-size 1600 \
    --track_buffer 60 \
    --device "0" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/ \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --hide-labels-name

# 3. Inference on Video (without initial position)
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source ../data/demo/MOT/MultiUAV-003.mp4 \
    --img-size 1600 \
    --track_buffer 60 \
    --device "0" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/ \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --hide-labels-name

# 4. Inference on Video (with initial position)
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source ../data/demo/MOT/MultiUAV-003.mp4 \
    --with-initial-positions \
    --initial-position-config ../data/demo/MOT/TestLabels_FirstFrameOnly/MultiUAV-003.txt \
    --img-size 1600 \
    --track_buffer 60 \
    --device "0" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/ \
    --with-reid \
    --fast-reid-config logs/sbs_S50/config.yaml \
    --fast-reid-weights logs/sbs_S50/model_0016.pth \
    --hide-labels-name
```

</details>


<details><summary>Run Inference Using a Custom Trained Model</summary>

This project also supports flexible inference using a custom-trained model for any MOT task. Below are the instructions for reproducing the preview section.

```bash
$ cd BoT-SORT/
```

### 1. Multi-Class on a Walkway Scene

```bash
$ wget https://github.com/sunsmarterjie/yolov12/releases/download/v1.0/yolov12x.pt
$ wget https://github.com/FoundationVision/ByteTrack/raw/main/videos/palace.mp4
$ python tools/inference.py \
    --weights yolov12x.pt \
    --source palace.mp4 \
    --img-size 640 \
    --device "0" \
    --save_path_answer ./submit/palace/
```

### 2. Common Objects Underwater

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15828323.svg)](https://doi.org/10.5281/zenodo.15828323)

```bash
for f in ./videos/COU/*.mp4; do
    python tools/inference.py \
        --weights ./yolov12/runs/det/train/weights/best.pt \
        --source "$f" \
        --img-size 1600 \
        --device "0" \
        --save_path_answer ./submit/COU/
done
```

### 3. UAVDB

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.16342697.svg)](https://doi.org/10.5281/zenodo.16342697)

```bash
for f in ./videos/UAVDB/*.mp4; do
    python tools/inference.py \
        --weights ./yolov12/runs/det/train/weights/best.pt \
        --source "$f" \
        --img-size 1600 \
        --device "0" \
        --save_path_answer ./submit/UAVDB/
done
```

### 4. NPS-Drones dataset

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.16891919.svg)](https://doi.org/10.5281/zenodo.16891919)

```bash
for f in ./videos/NPS/*.mp4; do
    python tools/inference.py \
        --weights ./yolov12/runs/det/train/weights/best.pt \
        --source "$f" \
        --img-size 1600 \
        --device "0" \
        --save_path_answer ./submit/NPS/
done
```

</details>


<details><summary>Run Inference on macOS</summary>

This project also supports running inference on macOS. However, for efficiency reasons, performing both training and inference on a GPU is still recommended.

When running on macOS, the following limitations apply:

1. No GPU or MPS acceleration (CPU only).
2. ReID is not supported.
3. Initial position is not supported.

Below are two examples of running inference on macOS.

```bash
# 1. Inference on Multi-Class on a Walkway Scene
$ wget https://github.com/sunsmarterjie/yolov12/releases/download/v1.0/yolov12x.pt
$ wget https://github.com/FoundationVision/ByteTrack/raw/main/videos/palace.mp4
$ python tools/inference.py \
    --weights yolov12x.pt \
    --source palace.mp4 \
    --img-size 640 \
    --device "cpu" \
    --save_path_answer ./submit/palace/

# 2. Inference on MultiUAV Video
python tools/inference.py \
    --weights ./yolov12/weights/ViA_yolov12n.pt \
    --source ../data/demo/MOT/MultiUAV-003.mp4 \
    --img-size 1600 \
    --track_buffer 60 \
    --device "cpu" \
    --agnostic-nms \
    --save_path_answer ./submit/inference/
```

Inference time comparison for the two examples on GPU (Ubuntu) and CPU (macOS).

<img src="https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/assets/inference_ubuntu_mac.png" width="100%">

</details>








## ğŸ› ï¸ Implementation Details


<details><summary>Hardware Information</summary>

Experiments were conducted on two platforms: (1) a local system with an Intel Core i7-12650H CPU, NVIDIA RTX 4050 GPU, and 16 GB RAM for data processing and inference, and (2) an HPC system with an NVIDIA H100 GPU and 80 GB memory for model training.

### Laptop

<a href="https://github.com/wish44165/wish44165/tree/main/assets"><img src="https://github.com/wish44165/wish44165/blob/main/assets/msi_Cyborg_15_A12VE_badge.svg" alt="Spartan"></a> 

- CPU: IntelÂ® Coreâ„¢ i7-12650H
- GPU: NVIDIA GeForce RTX 4050 Laptop GPU (6GB)
- RAM: 23734MiB

### HPC

<a href="https://dashboard.hpc.unimelb.edu.au/"><img src="https://github.com/wish44165/wish44165/blob/main/assets/unimelb_spartan.svg" alt="Spartan"></a> 

- GPU: Spartan gpu-h100 (80GB), gpu-a100 (80GB)
  
</details>




### ğŸ–» Data Preparation


<details><summary>Officially Released</summary>

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15103888.svg)](https://doi.org/10.5281/zenodo.15103888)

```
4th_Anti-UAV_Challenge/
â”œâ”€â”€ baseline/
â”‚Â Â  â”œâ”€â”€ Baseline_code.zip
â”‚Â Â  â””â”€â”€ MultiUAV_Baseline_code_and_submissi.zip
â”œâ”€â”€ test/
â”‚Â Â  â”œâ”€â”€ MultiUAV_Test.zip
â”‚Â Â  â”œâ”€â”€ track1_test.zip
â”‚Â Â  â””â”€â”€ track2_test.zip
â””â”€â”€ train/
    â”œâ”€â”€ MultiUAV_Train.zip
    â””â”€â”€ train.zip
```

- Train
    - Track 1 & Track 2: [Google Drive](https://drive.google.com/drive/folders/1hEGq14WnfPstYrI_9OgscR1VsWc5_XDl) | [Baidu](https://pan.baidu.com/s/1rtZ_PkYX__Bt2O5MgTj1tg?pwd=CVPR)
    - Track 3: [Google Drive](https://drive.google.com/drive/folders/1JvGdAJjGzjOIGMG82Qiz5YJKzjy8VOd-?usp=drive_link) | [Baidu](https://pan.baidu.com/s/19iVwI1MW9OdXyPIc0xBSjQ?from=init&pwd=CVPR)
- Test
    - Track 1: [Google Drive](https://drive.google.com/drive/folders/1qkUeglLk9-OXniIUVh1r7OljDLwDNhBs?usp=sharing) | [Baidu](https://pan.baidu.com/s/13HFq5P0gWrdlBerFZBKbuA?pwd=cvpr)
    - Track 2: [Google Drive](https://drive.google.com/drive/folders/1qkUeglLk9-OXniIUVh1r7OljDLwDNhBs?usp=sharing) | [Baidu](https://pan.baidu.com/s/1s7KkyjgXP1v495EULqwoew?pwd=cvpr)
    - Track 3: [Google Drive](https://drive.google.com/drive/folders/1cfF00w_3ewUMELSSnmaYOKLTZoIWlxbF?usp=sharing) | [Baidu](https://pan.baidu.com/s/1rhB24tksTw1JW6ZltOSvOg?pwd=CVPR)

</details>


<details><summary>Strong Baseline</summary>

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15203123.svg)](https://doi.org/10.5281/zenodo.15203123)
[![Hugging Face Datasets](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Datasets-blue)](https://huggingface.co/datasets/wish44165/StrongBaseline_YOLOv12-BoT-SORT-ReID) 

```
train/
â”œâ”€â”€ MOT/
â”‚Â Â  â””â”€â”€ AntiUAV_train_val.zip
â”œâ”€â”€ ReID/
â”‚Â Â  â”œâ”€â”€ MOT20_subset.zip
â”‚Â Â  â””â”€â”€ MOT20.zip
â””â”€â”€ SOT/
    â”œâ”€â”€ AntiUAV_train_val_test.zip
    â””â”€â”€ AntiUAV_train_val.zip
```

</details>


<details><summary>Enhancements</summary>

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15276582.svg)](https://doi.org/10.5281/zenodo.15276582)

```
enhancements/
â”œâ”€â”€ MOT/
â”‚Â Â  â”œâ”€â”€ CLAHE_train_val.zip
â”‚Â Â  â”œâ”€â”€ Sobel-based_Edge_Sharpening_train_val.zip
â”‚Â Â  â””â”€â”€ Sobel-based_Image_Gradients_train_val.zip
â””â”€â”€ ReID/
    â”œâ”€â”€ CLAHE_subset.zip
    â”œâ”€â”€ Sobel-based_Edge_Sharpening_subset.zip
    â””â”€â”€ Sobel-based_Image_Gradients_subset.zip
```

</details>




### ğŸ“‚ Folder Structure

<details><summary>Project Layout</summary>

Follow the folder structure below to ensure smooth execution and easy navigation.

```
YOLOv12-BoT-SORT-ReID/
â”œâ”€â”€ BoT-SORT/
â”‚Â Â  â”œâ”€â”€ getInfo.py
â”‚Â Â  â”œâ”€â”€ datasets/
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ fast_reid/
â”‚Â Â  â”‚Â Â  â””â”€â”€ datasets/
â”‚Â Â  â”‚Â Â   Â Â  â”œâ”€â”€ generate_mot_patches.py
â”‚Â Â  â”‚Â Â   Â Â  â””â”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ logs/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ sbs_S50/
â”‚Â Â  â”‚   â”‚Â Â  â”œâ”€â”€ config.yaml
â”‚Â Â  â”‚   â”‚Â Â  â””â”€â”€ model_0016.pth
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ requirements.txt
â”‚Â Â  â”œâ”€â”€ runs/
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ submit/
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â”œâ”€â”€ tools/
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_track1.py
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict_track2.py
â”‚Â Â  â”‚Â Â  â””â”€â”€ predict_track3.py
â”‚Â Â  â””â”€â”€ yolov12/
â”‚Â Â      â”œâ”€â”€ heatmap.py
â”‚Â Â      â”œâ”€â”€ imgs_dir/
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 00096.jpg
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 00379.jpg
â”‚Â Â      â”‚Â Â  â”œâ”€â”€ 00589.jpg
â”‚Â Â      â”‚Â Â  â””â”€â”€ 00643.jpg
â”‚Â Â      â”œâ”€â”€ requirements.txt
â”‚Â Â      â””â”€â”€ weights/
â”‚Â Â       Â Â  â”œâ”€â”€ v1/
â”‚Â Â          â”‚   â”œâ”€â”€ MOT_yolov12n.pt
â”‚Â Â          â”‚   â””â”€â”€ SOT_yolov12l.pt
â”‚Â Â          â””â”€â”€ ViA_yolov12n.pt
â”œâ”€â”€ data/
â”‚Â Â  â”œâ”€â”€ demo/
â”‚Â Â  â”œâ”€â”€ MOT/
â”‚Â Â  â”‚Â Â  â””â”€â”€ README.md
â”‚Â Â  â””â”€â”€ SOT/
â”‚Â Â      â””â”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

</details>




### ğŸ”¨ Reproduction

<details><summary>Run Commands</summary>

Executing the following commands can reproduce the leaderboard results.

<details><summary>Data Analysis</summary>

```bash
$ cd BoT-SORT/

# Table 1
$ python getInfo.py
```

</details>

<details><summary>Train YOLOv12</summary>

Refer to the [README](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/tree/main/data/MOT#readme) for more information.

```bash
$ cd BoT-SORT/yolov12/

# Run training with default settings
$ python train.py
```

</details>

<details><summary>Train BoT-SORT-ReID</summary>

Refer to the [README](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/tree/main/BoT-SORT/fast_reid/datasets#readme) for more information.

```bash
$ cd BoT-SORT/

# Train with final config
$ python fast_reid/tools/train_net.py --config-file ./logs/sbs_S50/config.yaml MODEL.DEVICE "cuda:0"
```

</details>

<details><summary>Inference</summary>

```bash
$ cd BoT-SORT/

# Track 1
$ python tools/predict_track1.py --weights ./yolov12/weights/v1/SOT_yolov12l.pt --source ../data/SOT/track1_test/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 4 --save_path_answer ./submit/track1/test --hide-labels-name
# output: ./runs/detect/, ./submit/track1/test/

# Track 2
$ python tools/predict_track2.py --weights ./yolov12/weights/v1/SOT_yolov12l.pt --source ../data/SOT/track2_test/ --img-size 640 --device "0" --conf-thres 0.01 --iou-thres 0.01 --track_high_thresh 0.1 --track_low_thresh 0.01 --fuse-score --agnostic-nms --min_box_area 1 --save_path_answer ./submit/track2/test --hide-labels-name
# output: ./runs/detect/, ./submit/track2/test/

# Track 3
$ chmod +x run_track3.sh
$ ./run_track3.sh
# output: ./runs/detect/, ./submit/track3/test/
```

</details>

</details>








## âœ¨ Models

[![Hugging Face Models](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-blue)](https://huggingface.co/wish44165/YOLOv12-BoT-SORT-ReID) 

| Model                                                                                | size<br><sup>(pixels) | AP<sup>val<br>50-95 | params<br><sup>(M) | FLOPs<br><sup>(G) | Note |
| :----------------------------------------------------------------------------------- | :-------------------: | :-------------------:| :-----------------:| :---------------:| :----: |
| [SOT_yolov12l.pt](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/BoT-SORT/yolov12/weights/v1/SOT_yolov12l.pt) | 640                   | 67.2                 | 26.3                | 88.5               |
| [MOT_yolov12n.pt](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/blob/main/BoT-SORT/yolov12/weights/v1/MOT_yolov12n.pt) ([ReID](https://huggingface.co/wish44165/YOLOv12-BoT-SORT-ReID/tree/main)) | 1600                   | 68.5                 | 2.6                | 6.3              | [#4 (Comment)](https://github.com/wish44165/YOLOv12-BoT-SORT-ReID/issues/4#issuecomment-2959336418) |








## ğŸ“œ Citation

If you find this project helpful for your research or applications, we would appreciate it if you could cite the paper and give it a star.

```
@InProceedings{Chen_2025_CVPR,
    author    = {Chen, Yu-Hsi},
    title     = {Strong Baseline: Multi-UAV Tracking via YOLOv12 with BoT-SORT-ReID},
    booktitle = {Proceedings of the Computer Vision and Pattern Recognition Conference (CVPR) Workshops},
    month     = {June},
    year      = {2025},
    pages     = {6573-6582}
}
```

<a href="https://www.star-history.com/#wish44165/YOLOv12-BoT-SORT-ReID&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=wish44165/YOLOv12-BoT-SORT-ReID&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=wish44165/YOLOv12-BoT-SORT-ReID&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=wish44165/YOLOv12-BoT-SORT-ReID&type=Date" />
 </picture>
</a>








## ğŸ™ Acknowledgments

Much of the code builds upon [YOLOv12](https://github.com/sunsmarterjie/yolov12), [BoT-SORT](https://github.com/NirAharon/BoT-SORT), and [TrackEval](https://github.com/JonathonLuiten/TrackEval). We also sincerely thank the organizers of the [Anti-UAV](https://github.com/ZhaoJ9014/Anti-UAV) benchmark for providing the valuable dataset. We greatly appreciate their contributions!